[TOC]



## 网络

#### （1）什么是HTTP？

HTTP，超文本传输协议的缩写，互联网广泛使用的一种网络协议，定义了客户端和服务端之间的文本传输规范。服务端默认使用80端口，客户端使用端口是动态分配的。由客户端发起请求，建立一个与服务器指定端口的TCP连接（可以引出TCP和UDP有什么不同，使用TCP的原因是打开一个网页会传送很多数据，TCP协议提供了传输控制，按序交付，错误纠正，在HTTP/3中使用UDP）



#### （2）HTTP 请求方式

- GET，请求指定的页面信息，并返回实体主体
- POST，向指定资源提交数据进行处理请求（如提交表单等），数据包含在请求体中
- HEAD，用于获取报头
- PUT，从客户端向服务端传送的数据取代指定的文档的内容
- DELETE，请求服务器删除指定页面
- TRACE，回显服务器收到的请求，主要用于测试或诊断
- CONNECT，HTTP/1.1中预留给能够将连接改为管道方式的代理服务器
- OPTIONS，允许客户端查看服务端性能

其中GET和POST的区别：
GET一般用于向服务器获取数据，没有请求体，仅支持ASCII码，安全，幂等，明文，可缓存的
POST一般用于向服务器发送数据，有请求体，支持标准字符集，不安全的，非幂等，不可缓存



#### （3）HTTP/1.0 vs HTTP/1.1

HTTP/1.1 默认采用持久连接，在一个TCP连接上可以传送多个HTTP请求和响应，减少建立和关闭连接到消耗和延迟。

HTTP/1.1 允许客户端流水线操作，不用等待上一次请求到结果返回就可以发送下一次请求，以减少整个过程的时间消耗

HTTP/1.1 中Header中可以有Connection，当其值为close时，正在使用的TCP连接在请求处理完毕后就会被断掉，当其值均为Keep-alive时保持连接

HTTP/1.1 增加了请求头和响应头来改进和扩充HTTP/1.0的功能，如Host（支持一台Web服务器在同一个IP地址和端口上使用不同的主机名来创建多个虚拟Web站点），提供缓存控制策略（如Entity tag，If-Unmodified-Since，If-Match，If-None-Match等），支持断点续传（Range，状态码对应206），增加错误状态响应码，引入Cookie保存状态信息



#### （4） HTTP/2.0

多路复用：允许通过单一的HTTP/2连接发起多重的请求-响应消息，主要解决HTTP/1.1的串形文件传输【借助二进制分帧+流】和连接数限制问题【借助流】

二进制分帧：在HTTP/2和传输层（TCP or UDP）之间增加二进制分帧，改进传输性能

首部压缩：DEFLATE算法（SPDY算法，强制使用HTTPS），HPACK算法，每个请求都要发送消息头，通过维护一个词典差量更新

服务端推送：在客户端请求发送之前发送数据，可以缓存数据



#### （5）HTTP vs HTTPS

HTTPS = HTTP + SSL/TLS（Secure Sockets Layer，涉及非对称加密，对称加密，HASH算法，序列号机制防止重放）

HTTPS 要求在传输数据之前客户端和服务器之间进行证书认证、密钥协商，

TLS过程：

* 浏览器将一套加密规则（对称加密算法、非对称加密算法、MAC算法、Nonce）发送给服务器
* 服务器从中选择一组加密算法和MAC算法，并将自己的身份信息以证书的形式（网址、加密公钥、证书颁发机构、过期时间等）发送给浏览器
* 浏览器验证证书合法性，生成一串随机数作为**通信密钥**，并使用约定的HASH算法计算握手信息，使用通信密钥对握手信息加密，通信密钥用服务器的公钥加密，都发送给服务器
* 服务器使用私钥解密获取通信密钥，再使用通信密钥解密握手信息并验证HASH值，验证完成后使用通信密钥加密一段握手信息发送浏览器
* （协商完通信密钥之后重新进行一次加密规则的协商 === *有内鬼，终止交易*）
* 浏览器使用通信密钥解密握手消息并计算HASH，并验证。
* 之后所有的通信都使用通信密钥进行通信（如果报文太大，TLS会做分割形成多个记录，序列号也会在MAC算法中作为输入）

主要区别：证书、明文/密文传输、端口443/80

HTTPS通信过程（分为ECDHE握手、RSA握手，不同之处在于RSA握手是直接由客户端生成）：

- 客户端与服务器首先建立TCP连接（DNS获取IP，然后TCP三次握手）
- 客户端向服务端443端口发起请求（Client Hello），将一套算法（支持的协议版本、支持的加密算法、Hash算法、Nonce1）发送给服务器
- 服务器选择算法（确认版本、确认加密算法），并将自己的信息（网址、公钥、证书颁发机构、证书过期时间）【通过证书形式】和Nonce2发送给客户端
- 客户端验证证书合法性，验证通过后生成随机值（Nonce3，与Nonce1和Nonce2一起生成session key和MAC key），使用服务器的公钥加密将“握手信息（改用会话密钥通信和所有握手数据的摘要）” 都发送给服务器 
- 服务器解密，验证Hash值，并生成响应的密钥，发送“握手信息（改用会话密钥通信和所有握手数据的摘要）”给客户端
- 服务器和客户端之后的通信用协商的密钥进行请求/响应

[参考链接](http://www.360doc.com/content/20/1119/19/37113458_946750481.shtml)：建议查看，比这里更详细，有图更容易理解

由IETF正是标准化SSL后称为TLS，版本号从1.0重新计算，所以SSL v3.1即TLS1.0，当前广泛使用的是TLS1.2。

TLS由记录协议、握手协议、警告协议、变更密码规范协议、扩展协议等几个字协议组成，算法的组合称为“密码套件“。在TCP建立连接的基础上，完成另一个”握手“过程，以此建立安全连接。

- 记录协议，规定TLS收发数据的基本单位
- 警报协议，向对方发出警报信息
- 握手协议，完成TLS版本号、随机数、密码套件等的协商，交换整数和密钥参数，获得回话密钥
- 变更密码规范协议，通知对方，后续数据均采用加密保护

ECDHE握手过程：

- ClientHello（客户端随机数C，客户端TLS版本号，密码套件列表，扩展列表） ->
- <-ServerHello（服务端随机数S，确认TLS版本号，使用的密码套件，Server Certificate，Server Key Exchange（交换参数并签名验证），ServerHello Done
- Client Key Exchange（交换参数，并通过ECDHA计算pre-master），Change Cipher Spec，Finished（所有握手数据的摘要） ->
- GET HTTP/1.1 ->【TLS False Start，与TCP Fast Open相似，不等到连接完全建立就提前发送应用数据，提高传输效率】
- <- Change Cipher Spec，Finished（所有握手数据的摘要），HTTP/1.1 200 OK

RSA握手过程：

- Client Hello（客户端随机数C，客户端TLS版本号，密码套件列表，扩展列表）
- <-ServerHello（服务端随机数S，确认TLS版本号，使用的密码套件，Server Certificate，Server Key ExchangeKey，ServerHello Done\
- Client Key Exchange（RSA公钥加密pre-master），Change Cipher Spec，Finished（所有握手数据的摘要） ->
- <- Change Cipher Spec，Finished（所有握手数据的摘要）
- GET HTTP/1.1 ->【TLS False Start，与TCP Fast Open相似，不等到连接完全建立就提前发送应用数据，提高传输效率】
- <- HTTP/1.1 200 OK



#### （6）TCP和UDP有什么不同

TCP：面向连接的、可靠（三次握手+四次挥手、校验和、序列号、超时重传、流量控制、拥塞控制、确认应答机制）交付、流量控制、拥塞控制、全双工、面向字节流、仅支持一对一

UDP：无连接的、尽最大可能交付、面向报文、支持点对点+多播+广播



#### （7）TCP 3次握手和4次挥手

三次握手：（两次握手不行是因为只能客户端的起始序列号被确认，而服务端的序列号不会被确认，不一定可靠）

* 客户端发送数据包（SYN=1，seq=x），进入syn_sent状态，等待服务端确认
* 服务端回复数据包（SYN=1，ACK=x+1，seq=y），进入syn_rcvd状态（此时请求连接被放在半连接队列中，SYN攻击--发送大量半连接请求，占用半连接队列，耗费CPU和内存，可以通过缩短SYN Timeout事件或者限制给定IP的半连接数目来防范）
* 客户端确认数据包（ACK=y+1，seq=x+1），双方进入established状态

四次挥手：（双方确认对方的连接关闭，等待2MSL的原因是保证上一次连接的报文已经从网络中消失并且接收重发的第四次挥手）

* 客户端发送数据报（FIN=1，seq=z），进入fin_wait_1状态
* 服务端回复数据包（ACK=z+1），进入close_wait状态（半关闭状态，客户端已经没有要发送的数据但可以接受服务端的数据），客户端在接收到ACK之后进入fin_wait_2状态
* 服务端发送数据包（FIN=1，seq=w），进入last_ack状态
* 客户端回复数据包（ACK=w+1）后进入time_wait状态，服务端接收到ACk后进入closed状态，客户端在等待2MSL后进入closed状态



#### （8）session 和 Cookie的区别

session： 由服务端产生，保存在服务端，session id存放在cookie中，一般用于用户验证

cookie： 由服务端产生，在客户端保存，一般用于标识客户端



#### （9）浏览器从输入网址到显示整个页面的经历

* 对域名进行格式化检查
* 根据域名查看本地缓存（检查是否过期，更新资源刷新缓存或读取缓存）
* 根据域名通过DNS解析得到IP地址，会经过ARP（广播询问，单播回复）获取网关的MAC地址，将数据包发送给网关，由网关交付给本地DNS服务器，查询IP地址，DNS查询会经历浏览器缓存-操作系统缓存-路由器缓存-ISP DNS 缓存-根域名服务器
* 与服务器指定端口建立TCP连接，经历三次握手（也需要经过上面的走网关交付路由器流程），建立连接后，发送HTTP请求，转成TCP报文交付给路由器，经过IP路由后交付给服务器，中间会经过MAC地址变化
* 服务器处理请求并回复
* 浏览器接收到响应资源后，对响应资源进行处理并解析响应内容
* 由浏览器内核对页面进行渲染（DOM树、CSS规则树、渲染树、JS执行）



#### （10） 网络协议模型

OSI七层协议：物理层（二进制比特流传输）、数据链路层（封装成帧，透明传输，差错检测CRC）、网络层（路由选择算法，IP首部，ARP、ICMP、IGMP，路由器，RIP/OSPF、BGP）、传输层（拥塞控制、流量控制、差错控制，提供进程间的逻辑通信）、会话层（建立--身份+权限、保持--维护、断开--释放）、表示层（数据格式编译）、应用层（HTTP协议、FTP协议等）

TCP/IP五层协议包括：物理层，数据链路层，网络层，运输层，应用层



#### （11）TCP粘包

由于TCP是面向字节流的，可能会出现以下情况：

- 发送方采用了优化算法（Nagle算法），多个小尺寸数据可能会被封装在一个TCP报文中，而接收方一次性读完。
- 由于应用程序从缓存中读取数据包的速度小于TCP接收数据包到缓存的速度，则多个包会一起缓存，应用程序可能读取到多个首尾相接粘到一起的包

何时处理：当多个分组毫不相干，甚至是并列关系时必须处理

处理方法：

- 如果是发送方造成的粘包现象，可以关闭Nagle算法（TCP_NODELAY）；
- 如果是接收方造成的，只能向上交给应用程序处理。
- 还有一种统一的处理方式是在直接在应用层处理，固定发送消息长度或加入消息分隔符

UDP是面向消息传输的，消息有保护边界，所以不会造成粘包问题。



#### （12）滑动窗口（流量控制） vs  拥塞控制 vs 差错控制

滑动窗口：接收方告知发送方 -- 接收窗口的大小，从而控制发送方的速度

拥塞控制：发送方维护拥塞窗口大小，慢开始（每接一次报文，指数增加）、拥塞避免（经过一个RTT，拥塞窗口加1）、快恢复（拥塞时将门限值设置为拥塞时发送窗口的一半，并将拥塞窗口设置为门限值）、快重传（三个ACK，不需要等待计时器超时）

差错控制：校验和、ACK、超时重传



#### （13）DNS协议

基于UDP的应用层协议，功能是根据域名解析出IP地址。

过程：

* 客户端发出查询请求，先在本地缓存中查找，未找到则发送给dns服务器
* 本地dns服务器在自己区域内查找，未找到则本地缓存中查找，仍未找到则将请求发送给根域名服务器
* 根域名服务器解析根域部分，回复包含下一级的dns服务器给本地dns服务器
* 本地dns服务器根据返回的信息接着访问下一级的dns服务器（递归），获取IP信息
* 本地dns服务器将查询结果返回给客户机
* 客户机收到接收并添加缓存，完成解析过程



#### （14） ping命令使用哪些协议

ping命令使用的是ICMP协议（Internet控制报文协议，传输时封装在IP报文中）



#### （15）负载均衡

（1）什么是负载均衡

将工作负载分布到多个服务器来提高性能和可靠性的机制，涉及到的负载均衡算法有：轮询、最小连接、IP散列

（2）有哪些负载均衡？

七层（应用层）负载均衡：Nginx【用户态，相对比较重】

四层（传输层）负载均衡：LVS，修改报文头目标地址，如果需要也可修改源地址，接收到客户端的SYN请求时，通过负载均衡算法选择一个最佳服务器，并对报文中目标地址IP进行修改--最佳服务器IP，转发给该服务器，TCP建立连接（客户端和服务器直接建立连接，LVS只起到一个类似路由器转发的功能）【LVS是Linux内核模块，工作在内核态】

三层（网络层）负载均衡：基于IP地址分流

二层负载均衡：基于MAC地址分流，粒度粗

DNS负载均衡：在解析域名时随机调度，类似于HTTP重定向转换策略



#### （16）TCP 延迟确认

TCP在处理交互数据流时，采用延迟确认以及Nagle算法来减少小分组数目

Nagle算法是为了尽可能发送大块数据，避免过多的小分组数目在网络中。基本定义：任意时刻，最多只能有一个未被确认的小段（小于MSS尺寸的数据块没有收到ACK）
基本规则：

- 如果包长度大于MSS，则允许发送
- 如果包含有FIN，则允许发送
- 设置TCP_NODELAY选项，则允许发送
- 未设置TCP_CORK选项时，若所有发出去的小数据包均被确认，则允许发送
- 上述条件不满足但发生了超时（200ms），则立即发送

**Nagle事实上就是一个扩展的基于包的停止-等待协议。**

延迟确认：TCP在接收到对端端报文后，不会立即发送ACK，而是等待一段时间发送ACK，以便将ACK和要发送的数据一块发送。
规则：

1. 当有响应数据发送时，ACK随数据一起发送
2. 没有响应数据，则ACK会有延迟，以等待是否有响应数据一起发送，但延迟一般在40ms-500ms之间（内核启动一个定时器，每个200ms就会检查一次，而不是设置某个时间值当定时器）
3. 如果在等待发送ACK期间，第二个数据又到了，则立即发送ACK

Cork算法：TCP不关注是否有收到ACK报文，只有当前缓存中积累的数量不足以组成一个full-size数据包时就不会将数据包发出，直到一个RTO超时才会把不满足full-size的数据包发送出去。
由TCP_CORK选项设置，优先级比TCP_NODELAY高。



#### （17） RPC vs HTTP 

RPC：远程过程调用，基于原生TCP通信，可自定义数据格式，速度快、效率高，需要双方使用相同的技术

HTTP：网络传输协议，基于TCP，规定了数据传输格式，但不关注语言的实现

二者都会基于socket，都可以实现远程调用，实现服务调用服务



#### （18） socket vs websocket vs HTTP长连接

HTTP长连接：本质上是请求/响应模式

WebSocket HTML5下的一种新协议，属于服务器推送技术的一种，握手使用HTTP实现（Upgrade/Connection/Sec-WebSocket-\*），本身属于应用层协议，复用了HTTP的握手通道，实现了浏览器和服务器的全双工通信，不同于HTTP长连接的地方是HTTP长连接是请求-响应模式，需要消息头【与socket其实没什么关系】

Socket 对TCP/IP协议的封装，只是接口而不是协议，一般情况下就是TCP连接。



#### （19）RESTful

Representational State Transfer，表现层状态转换

RESTful 架构：

- 有一种资源，每种资源有唯一的URI来标识
- 对这种资源进行操作，实现状态转换，通常用HTTP方法来操作
- 客户端对服务器资源进行操作

RESTful API基于REST架构设计理念下利用HTTP协议描述和操作接口，主要涉及URL的设计、Request参数、Response数据

- URL的设计需要简单易懂，【协议】【域名】【路径】【方法】【参数】
- 常用的动作方法：

| 动作   | 说明                         |
| ------ | ---------------------------- |
| GET    | 读取 Read                    |
| POST   | 新建 Create                  |
| PUT    | 更新 Update                  |
| PATCH  | 更新 Update ，一般为部分更新 |
| DELETE | 删除 Delete                  |

- **其他操作：**

| 方法/资源 | http://example.com/users              | http://example.com/users/23 |
| --------- | ------------------------------------- | --------------------------- |
| GET       | 获取所有的用户信息                    | 获取用户id为23的信息        |
| POST      | 在所有用户信息中创建/追加一个新的用户 | 在id=23号用户新增信息       |
| PUT       | 更新该组用户信息                      | 更新id=23号的用户信息       |
| DELETE    | 删除所有的用户信息                    | 删除id=23号用户信息         |
| PATCH     | 更新所有用户部分信息                  | 更新id=23号用户信息         |

- URL的层级，可以定义为`GET /uesr/10/articales`，也可以定义为`GET /articles?user_id=10`

- 域名设计，可以采用独立域名`api.example.com`，也可以采用`example.com/api/users`。便于迁移

- 版本号，考虑到系统变化、迭代、兼容性，在API中引入版本号，可以在URL中加入版本号`GET api.example.com/v1/users`【便于操作】，也可以在请求头信息中加入`Accept: applicatio/example.com+json; version=3`【基于同一种资源的不同表现形式】

- 可选、复杂参数使用查询字符串

  - 过滤

    **比如某一个用户已经发表的文章**：
    `GET /users/10/posts?state=published`
    `GET /users/10/posts?published=true`

  - 分页

    **比如用户分页**：
    `GET /users?page=1&page_size=10`

    **在加条件，某一个用户已经发表的文章太多，需要分页**：
    `GET /users/10/posts?published=true&page=2&page_size=10`

  - 多字段排序

    **针对多个字段，不同的排序：**
    搜索用户，并按照注册时间升序、活跃度降序
    `GET /users?q=key&sort=create_time_asc,liveness_desc`

  - 显示某些字段

    `GET /users?fields=id,title,desc;`

  - github的api查看地址：**https://api.github.com/**

- 非资源特殊请求

  `GET /translate?from=de_DE&to=en_US&text=Hallo`
  `GET /calculate?para2=23&para2=432`

  在这种情况下，API响应不会返回任何资源。而是执行一个操作并将结果返回给客户端。因此，您应该在URL中使用动词而不是名词，来清楚的区分资源请求和非资源请求。

- 返回格式和状态码统一

- 最好做到Hypermedia即返回结果中提供链接，连向其他API方法，使用户不查阅文档也知道下一步应该做什么

- 设计技巧

  - `/`表示资源层级关系
  - `?`过滤资源
  - `,`或`;`表示资源同级层关系
  - `_`或`-`比啊时更友好的URL形式



#### （20）TCP长短连接

TCP短连接：一般只会在客户端和服务器之间传递一次读写操作，易于管理，存在的连接都是有效连接

TCP长连接：根据下面的保活机制，探测长连接存活状态，但如果探测周期太长或恶意连接将导致服务器资源浪费，所以在长连接下，客户端一般不会主动关闭连接，由服务端根据不同的策略关闭一些连接。适用于操作频繁，点对点的通讯。



#### （21）TCP保活机制

主要为服务器应用提供，服务器希望知道客户端主机是否崩溃，从而代表客户端使用资源，如果客户端已经消失，而服务器却在等待客户端的数据，此时保活机制就用于尝试在服务器检测这种半开放的连接

如果一个给定连接在两小时内没有动作，则服务器向客户端发送一个探测报文，客户端主机必须处于以下4个状态：

- 正常运行，并服务器可达，则响应正常
- 已崩溃或重启中，客户端没有响应，服务器也收不到探测的响应，并在75s后超时，服务器发送10次这样的报文，间隔时间75s，如果未收到任何一个响应，认为客户端已经关闭并终止连接
- 已重启，服务器将收到一个响应（复位），此时服务器终止这个连接
- 正常运行，但服务器不可达，与第二种情况类似



#### （22）UDP如何实现可靠传输即RUDP

首先，对“可靠”进行定义：

- 尽力可靠，接收方要求发送方数据尽量完整到达，但业务本身数据允许缺失（音视频数据、幂等性等）
- 无序可靠，接收方要求发送方数据必须完整达到，但可以不处理到达先后顺序（文件传输、白板书写、图形实时绘制，日志型追加数据等）
- 有序可靠，接收方要求发送方数据必须按顺序完整到达

其次，为什么不直接使用TCP而要用UDP实现可靠传输？这是因为RUDP主要解决以下问题：

- 端对端连通性问题，一般而言端到端的通信涉及到NAT穿透，TCP在NAT穿透中实现非常困难，但相对来说UDP却简单很多。场景有：端到端的文件传输、实时音视频传输、交互指令传输等等
- 弱网环境传输问题，在Wi-Fi或3/4G移动网络下，要实现低延迟可靠通信，如果使用TCP通信延迟可能会影响到用户体验。场景有：实时操作类网游、语音通话、多方白板书写等
- 带宽竞争问题，客户端数据上传需要突破本身TCP公平性来达到高速低延迟和稳定，需要用到特殊的流量控制来压榨客户端上传带宽。场景有直播音视频推流
- 传输路径优化问题，在一些对延时要求很高的场景下，会用应用层relay的方式来做传输路由优化即动态智能选路，双方均采用RUDP方式来传输，中间的延迟进行relay选路优化延迟。另一种是基于传输吞吐量的场景。场景有：服务与服务之间数据分发、数据备份等
- 资源优化问题，为了避免TCP的三次握手和四次挥手过程，采用RUDP优化资源占用率和响应时间，提高并发能力如QUIC

最后，怎么做到”可靠“？答案是**重传**呗，因为IP协议在设计时就不是为了数据可靠到达的，所以UDP必须依靠重传来实现可靠。

RUDP的重传是发送端通过接受端ACK的丢包信息反馈进行数据重传，发送端会根据场景设计重传方式

- 定时重传

  发出数据包后的一段时间内没有收到对数据包的ACK，则发送端重传该数据包。容易误判：

  - 对方收到了数据包，但ACK发送途中丢失
  - ACK在途中但计时器超时

  此时就要求这个计时器时间的计算尽可能准确，场景如果是一个对延迟敏感但对流量成本要求不高的场景，就可以将这个时间设计的比较小，从而保证延迟足够小。

  适用场景：实时操作类网游、白板同步

- 请求重传

  接受端在发送ACK时携带自己丢失报文的信息反馈，发送方在接收到ACK时根据丢包反馈进行重传。此过程要求设计ACK中应该携带哪些丢失报文的信息，因为UDP在网络传输时会乱序抖动，接收方需要评估网络的jitter time即rtt_var（RTT方差），当发现丢包的时刻记录，在过了rtt_var后，认为丢失。

  在网络不优的情况下，接收端会不断发起重传请求，造成发送方不停地重传，引起网络风暴，通信质量下降，此时要引入拥塞控制模块来限流。

  延迟相较于定时重传较大，适合于带宽较大的传输场景如视频、文件传输、数据同步等

- FEC（Forward Error Correction）选择重传

  一种前向纠错技术，通过类似XOR的算法实现，也有多层的EC算法和raptor涌泉码等

  发送方发送报文时，根据纠错技术将几个报文进行FEC分组，通过XOR的方式得到若干个冗余包，一起发送给接收方，如果接收方可以根据收到的包恢复出原始数据则不再请求重传，否则请求重传。

  适用于解决要求延时敏感且随机丢包的传输场景，在带宽有限的情况下可能会损害网络状况。

拥塞算法 -- BBR

主要策略是周期性通过ACK和NACK返回来评估链路的min_rtt和max_bandwidth，cwnd=max_bandwidth/min_rtt，致力于解决如下问题：

- 在一定丢包率网络传输链路上充分利用带宽
- 降低网络传输中buffer延迟

通过探测带宽和Pacing rate的状态：Startup（启动，增益参数为max_gain=2.85），DRAIN（满负荷），PROBE_BW（带宽评估，max_gain=1.25 用于递增 or 0.75 用于递减），PROBE_RTT（延迟评估，维持一个最小发送窗口--4个MSS进行RTT采样）



#### （23）代理

正向代理：隐藏真实的请求客户端，服务端不知道真正的客户端是谁。可以参考VPN

反向代理：隐藏了真实的服务端，客户端不知道真正提供服务的是谁。可以参考Nginx


------



## Linux

#### （1）awk

|      内部变量      |           含义           |
| :----------------: | :----------------------: |
|         $0         |          当前行          |
| \$1,\$2,\$3...,\$n |    当前行的第n个字段     |
|         NF         |     当前行的字段数目     |
|       FNR/NR       |           行号           |
|         FS         |     分隔符，默认空格     |
|        OFS         |   输出分隔符，默认空格   |
|         RS         |   行分隔符，默认换行符   |
|        ORS         | 输出行分隔符，默认换行符 |
|      FILENAME      |     当前处理的文件名     |

支持正则表达式
 `/root/{ statements}` 匹配所有包含“root”的行，对应sed中`/root/p`
`$5~/root/{statements}` 匹配第5个字短包含“root”的行

支持地址定位 
`NR==1,NR==5 {statements}` 打印第2行到第5行，对应sed中`1,5p`

#### （2）sed

```shell
sed [-hnV][-e<script>][-f<script文件>][文本文件]
```

参数说明：

- -e\<script\>或--expression=\<script\> 以选项中指定的script来处理输入的文本文件。
- -f\<script文件\>或--file=\<script文件\> 以选项中指定的script文件来处理输入的文本文件。
- -h或--help 显示帮助。
- -n或--quiet或--silent 仅显示script处理后的结果。
- -V或--version 显示版本信息。

动作说明

- a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)

- c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！

- d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚；

- i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；

- p ：打印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～

- s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 将1-20行的old换成new

  

#### （3）grep

```shell
grep [-abcEFGhHilLnqrsvVwxy][-A<显示行数>][-B<显示列数>][-C<显示列数>][-d<进行动作>][-e<范本样式>][-f<范本文件>][--help][范本样式][文件或目录...]
# -o 只输出匹配的行
# -x 只输出没有匹配的韩
# -n 打印匹配的行号
# -i 忽略大小写
# -I 只打印文建明
```



#### （4） wc

```shell
wc [-clw][--help][--version][文件...]
```

**参数**：

- -c或--bytes或--chars 只显示Bytes数。
- -l或--lines 显示行数。
- -w或--words 只显示字数。
- --help 在线帮助。
- --version 显示版本信息。

默认情况下计算行数、字数、字节数



#### （5）find

```shell
find [-H | -L | -P] [-EXdsx] [-f path] path ... [expression]
```



#### （6）xargs

给命令传递参数的过滤器，可以将管道或标准输入数据转换为命令行参数，也可以从文件的输出中读取数据；可以将单行或多行文件输入转换为其他格式

-n 多行输出
-d 自定义分隔符
-I 指定一个替换字符串，每一个参数都会执行一次命令



#### （7）内存映射

将需要访问的文件映射到一个进程的虚拟地址内，访问虚拟地址相当于访问文件，从磁盘访问变成了内存访问。



#### （8）使用`kill -9`杀不掉一个进程怎么办？

发送SIGKILL信号给进程将其终止，两种情况下不适用：

（1）僵尸进程，已经释放了所有资源但没有被父进程释放，要等到父进程结束或重启才会被清除

```
$ ps -A -o stat,ppid,pid,cmd |grep -e '^[Zz]' # 寻找到僵尸进程
# -A 列出所有进程
# -o 自定义输出字段
# zZ 僵尸进程
kill -HUP [ppid]
```

（2）核心态进程，等待不可获得的资源，会忽略所有信号 => 只能重启



#### （9）exec 执行进程

exec实际上由一系列接口组成，存在多个变种，其中功能最为全面的是execve

```c++
// pathname，进程需要载入的可执行文件的路径
// argv，进程执行所需的参数
// envp，为进程定义的环境变量，一般以键值对字符串形式传入
int execve(const char *pathname, char *const argv[],char *const envp[]);
```

执行过程至少包括：

- 根据pathname指明的路径，将可执行文件的数据段和代码段载入当前进程的地址空间中
- 重新初始化堆和栈，操作系统可以在此使用地址空间随机化（用于改变堆和栈的起始地址，增强进程安全性）技术
- 将PC寄存器设置到可执行文件代码段定义的入口点，该入口点会最终调用main函数



#### （10）进程树

进程树根部是操作系统创建的第一个进程`init`，其进程ID（PID）、进程组ID（GID）、会话ID（SID）均为1。第二个进程是`kthread`，其GID和SID为0，因为不存在与用户进行交互的需求，所有有内核创建和管理的进程都是有它fork出来的，最后`init`进程会创建出一个`login`进程来要求用户登录，验证通过后，会从`login`中fork出`bash`进程即终端。

基于进程树结构，内核为进程建立了联系，并在此基础上提供了监控、回收、信号分发等一系列功能。

- 进程间监控:`wait`，对子进程进行监控，与`exec`类似，`wait`有多个变种，此处主要介绍`waitpid`。

  ```c++
  // pid，需要等待的子进程id
  // wstatus，用于保存子进程状态
  // options，一些选项
  pid_t waitpid(pid_t pid, int *wstatus, int options);
  ```

  **除了完成监控的功能外，还起到了回收已经运行结束的子进程和释放资源的作用。**

  如果父进程没有调用wait操作，或没来得及调用wait操作，就算子进程已经终止了，所占用的资源也不会完全释放。这种进程称为**僵尸进程**，内核会为僵尸进程保留其进程描述符和终止时的信息（waitpid中的status），以便父进程在调用wait时可以监控子进程状态。

  如果一个进程创建了大量子进程却从不调用wait，那么僵尸进程将会迅速占据进程可用的PID（内核中会为每一个进程设定最大可用PID的限制），使得后续的fork因内核资源不足而失败。

  如果父进程退出，那么子进程信息就不会再为父进程使用，也就没有必要保留，此时，所有的僵尸进程将由内核的第一个进程`init`通过wait的方式回收。

  


#### （11）进程组

为了方便应用程序进行进程管理，内核定义了由多个进程组合而成的“小集体”即**进程组**和**会话**

**进程组是进程的集合**，可以由一个或多个进程组成，默认情况下，父进程和子进程属于同一个进程组。子进程若要脱离当前进程组，可以通过调用`setpgid`创建一个新的进程组或移入已有的进程组。**其作用之一体现在对信号的处理，可以用于打断进程执行，与中断类似，不过是由软件产生的。应用程序可以调用`killpg`向一个进程组发送信号，这个信号会被发送给这个进程组中每个进程。**

**会话是进程组的集合**，可以由一个或多个进程组构成，一般情况下，父进程和子进程属于同一个会话，会话根据执行状态将进程组分为前台进程组、后台进程组。控制终端进程是会话与外界进行交互的窗口，负责接受用户发来的输入，用户启动一个终端时，这个终端就相当于一个会话。**在终端中输入CRTL+C，终端进程就会收到一个SIGINT信号，并将其发送给前台进程处理**，一般会导致**前台进程组**的所有进程退出，**后台进程组**不受该信号影响，可以继续执行。



#### （12） fork

优点：

- 简洁，与exec的组合可以认为是进程创建过程的进一步解耦：fork为进程搭建了骨架，而exec为进程添加血肉，分工清晰，解耦带来的好处是可以对子进程进行给中设定
- 同时fork强调了进程与进程之间的联系。

局限性：

- fork的接口依旧简洁，默认语义是构造与父进程一样的拷贝，使得父进程和子进程共享了大量状态，可能会出现一些看似违反直觉的行为，所以随着操作系统支持的功能越来越多，其代码实现愈发复杂。
- fork的实现与进程、内存管理等模块等的耦合程度过高，不利于内核代码的维护
- 性能太差，即使写时拷贝技术（Copy on Write）已经大大优化了性能，但对于大内存应用来说，建立内存映射都需要耗费大龄时间，fork的性能已经无法满足需要了
- 存在潜在的安全漏洞，父进程和子进程之间的联系可能会成为攻击者的切入点。
- 扩展性差、与异质硬件不兼容、线程不安全等

Linux提出了针对fork的多种替代方案如spawn、vfork、clone等。



#### （13）posix_spawn

POSIX提供的另一种创建进程的方式，最初是为不支持fork的机器设计的。

```c++
// pid会在posix_spawn返回时被写入新进程的PID
// file_actions和 attrp 被用于在pre-exec阶段完成一系列操作
int posix_spawn(pid_t *pid, const char *path, const posix_spawn_file_actions_t *file_actions, const posix_spawnattr_t *attrp, char *const argv[], char *const envp[]);
```

可以认为是fork和exec两者功能的结合：使用类似于fork的方法（或直接调用fork）获得一份进程拷贝，然后调用exec执行。

执行时间与原进程的内存无关，并非fork+exec的简单组合，性能更优



#### （14）vfork

特定场景下对fork的优化：在进程创建后立即使用exec的场景。vfork+exec与fork+exec相比，省去了一次地址空间拷贝，同时避免了vfork带来的潜在安全问题。

```c++
pid_t vfork(void);
```

功能相当于fork的裁剪版：从父进程创建子进程，但不会为子进程单独创建地址空间，而是让子进程与父进程共享同一地址空间。为保证正确性，在结束后会阻塞父进程，直到子进程调用exec或退出为止。

提升了fork的性能表现，但仍无法完全避免fork本身带来的安全问题。



#### （15）clone

Plan 9中首次提出rfork接口，能支持父进程和子进程之间的细粒度资源共享，被Linux借鉴提出clone：同样通过拷贝的方式创建新进程，允许应用程序通过参数对创建过程进行更多的控制，在功能方面也有一些扩展。

```c++
// flag，执行不需要复制的部分，如CLONE_VM用于避免复制内存，允许子进程与父进程使用相同的地址空间，从而达到vfork相似的效果
// stack，执行子进程栈的位置，解决了父进程和子进程共享地址空间时栈冲突的问题
// fn和arg指定进程创建完成后执行的函数和输入参数，函数执行完成后，子进程将终止并返回
int clone(int (*fn)(void *),void *stack, int flags, void *arg,...);
```



------------







## OS

#### （1）什么是OS

Operate System，操作系统，管理计算机软硬件资源的程序，提供给用户和硬件之间的接口，向上对用户程序提供接口，向下管理资源，负责处理器调度（公平、非阻塞、优先级）、内存管理（抽象足够大的虚拟内存内存空间，共享内存）、I/O（设备）管理（屏蔽不同设备之间的差异、提供并发访问）、文件系统（易用性）、健壮性管理、安全性管理，保证计算机资源公平竞争和使用，防止对计算机资源的非法侵占和使用，并保证自身正常运转。



#### （2）用户态和内核态

**为了避免操作系统和关键数据被用户程序破坏**，将处理器（CPU）的执行状态分为内核态和用户态。

**内核态**是操作系统管理程序执行时所处的状态，能够执行包含特权指令在内的一切指令，能够访问系统内所有的存储空间。

**用户态**是用户程序执行时处理器所处的状态，不能执行特权指令，只能访问用户地址空间。

用户程序运行在用户态，操作系统内核运行在内核态。

内核态与用户态切换方式：系统调用（软中断）、异常（内中断，由错误引起如文件损坏、缺页故障等）、外部中断（硬中断）



#### （3）虚拟内存

对主存的抽象，提供三个能力：

* 将主存看成一个存储在磁盘上的地址空间的高速缓存，主存中只保存活动区域，根据需要替换数据，高效利用主存
* 为每一个进程提供一致的地址空间，简化内存管理
* 保护进程的地址空间不被其他进程破坏

页面置换算法：

FIFO、LRU（最常用）、LFU

虚拟地址向物理地址的转换过程：

* 虚拟地址=虚拟页号+页偏移，首先查快表（存放在内存管理单元--MMU中的TLB）中页面映射关系，失败（可并行）则页表（虚拟页号->页框号）中找到页框号
* 真实地址=物理页地址+页偏移 

每个进程的控制信息中存储当前进程“页目录”的物理地址，通过这个地址找到“页目录”，其中存储物理内存页起始地址的“页表”，32位下这样的两级页表足够存储寻址空间为4GB大小的内存空间了。利用页表中存储的记录中存储的内存页起始地址（因为起始地址必然是对应一个4KB的页，所以低12位是全0，可以用这些位记录页相关信息如是否可读、可写、可执行、是否已经映射等信息 ）】

虚拟内存空间被划分为内核空间和用户空间，内核空间中会有内核栈。

*用户空间上除了栈、堆、代码库、数据段、代码段外，还会有一些额外的区域，如vdso和vvar时与系统调用相关的内存区域，也会映射一些匿名的内存区域用于完成缓存、共享内存等工作*

#### （4）进程通信 vs 线程通信

进程通信

​	匿名管道（pipe）：调用pipe函数创建，返回两个文件描述符，一个用于读，一个用于写，**只支持半双工通信（单向交替传输）**，只能在父子进程或兄弟进程中使用，随进程消亡而消亡，linux中用`|`表示，**存在于内存的特殊文件**，系统调用是`pipe`，返回两个描述符，一个读取端描述符`fd[0]`，一个写入端描述符`fd[1]`，使用`fork`创建子进程时会复制父进程的文件描述符，从而两个进程各有一组写入/读取描述符，从而实现跨进程通信，为了避免写入/读取混乱，创建子进程后，父进程关闭读取端，子进程关闭写入端。所以一般为了实现双向通信，需要创建两个管道。在shell中执行`A|B`时，A进程和B进程都是shell父进程的子进程，不存在父子关系。

​	命名管道（named pipe）：去除了管道（pipe）只能在父子进程中使用的限制，命名管道与文件系统共享一个名字空间，可以从文件系统中看到命名管道，常用于客户-服务应用程序中，命名管道用作客户端汇聚点。涉及到的命令是`mkfifo`，在文件系统中以文件形式存在，类型为`p`，通信数据遵循FIFO。

=> 对于管道通信，进程写入数据缓存在内核中，另一个进程读取也是从内核中读取，效率较低，管道随进程创建而创建，随进程消亡而消亡，不适合进程间频繁交换数据。

​	消息队列（message queue）：独立于读写进程而存在，任何有权限的进程都可以读写，支持多个进程，不需要进程自己提供同步方法，读进程可以根据消息类型选择性接收消息，但**通信不及时、大小受限（内核中每个消息体有一个最大长度限制，所有消息体总长度也有限制）、用户态和内核态的拷贝开销**。**消息队列是保存在内核中的消息链表**，发送数据时会分成一个一个独立数据单元即消息体（用户自定义的数据类型，发送方和接收方事先约定），进程从消息队列中读取消息体，内核就会将相应的消息体删除，**生命周期跟随内核**，如果没有释放则消息队列一直存在。

​	共享内存（shared memory）：**为了解决消息队列存在用户态和内核态数据拷贝的开销**，拿出一块虚拟空间映射到相同的物理内存中，速度最快，**通常需要使用信号量互斥访问**。不同于管道的地方是，**共享内存通信双方必须在同一台物理机器上**，而且访问方式是随机的，而非一端写一端读。**但使用全局变量在同一进程的进程间实现通信通常不称为共享内存**。

​	信号量（semaphore）：**为了解决多进程共享内存时同时修改的冲突，防止多进程共享资源，造成数据错乱**，引入信号量，本质上一个整型的计数器，用于多个进程提供对共享数据对象的访问，可用于**实现进程间的互斥和同步，而非缓存进程间通信的数据**。当初始化为1时，就代表互斥信号量；当初始化为0时，就代表同步信号量，可用于进程同步。

​	信号（signal）：**为了解决异常模式下的工作模式**，引入**信号**通知进程，与信号量不同，唯一的异步通信机制，用于通知接受进程某事件已经发生，传输信息量小（使用管道或套接字不划算而且不想建立连接，并需要对方立即作出回应），在Linux中，为了响应各种各样的事件，提供了几十种信号，分别代表不同含义，可以通过`kill -l`查看。
​	其中`CTRL+C`产生`SIGINT`信号，表示终止该进程，`CTRL+Z`产生`SIGSTOP`信号，表示停止该进程但未结束，`kill -9 [pid]`给指定进程发送`SIGKILL`信号用于立即结束该进程。
​	用户进程对信号的处理方式有：（1）执行系统为信号规定的默认操作，（2）捕捉信号，自定义一个信号处理函数，当信号发生时，执行相应的信号处理函数，（3）忽略信号
​	**【注意】`SIGKILL`和`SIGSTOP`信号是无法捕捉和忽略的**，用于在任何时候中断或结束某一进程

​	Socket：可以实现跨网络与不同主机进程通信，也可以用于同主机上进程通信，系统调用是`int socket(int domain,int type,int protocal)`，domain用于指定协议族（AF_INET用于IPv4，AF_INET6用于IPv6，AF_LOCAL/AF_UNIX用于本机），type用语指定通信特性（SOCK_STREAM字节流，SOCK_DGRAM数据报，SOCK_RAW原始套接字），protocal指定通信协议（基本已废弃，一般写0），根据socket类型根据参数而确定

针对TCP协议通信的socket编程模型

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdrci5jbi1iai51ZmlsZW9zLmNvbS9iMDU3MmRkOS03YTI1LTQ0OTUtOWIyZS0wZTg1NjM0MTg1ZTMucG5n?x-oss-process=image/format,png)

针对UDP协议通信的socket编程模型

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdrci5jbi1iai51ZmlsZW9zLmNvbS82NTRjY2Y3NC02MWJkLTQ3OTItYWNlZi1jYWI3ZWUwZGM5YzkucG5n?x-oss-process=image/format,png)

针对本地通信的socket编程模型

本地 socket 被用于在同一台主机上进程间通信的场景：

本地 socket 的编程接口和 IPv4 、IPv6 套接字编程接口是一致的，可以支持「字节流」和「数据报」两种协议；
本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现；
对于本地字节流 socket，其 socket 类型是 AF_LOCAL 和 SOCK_STREAM。
对于本地数据报 socket，其 socket 类型是 AF_LOCAL 和 SOCK_DGRAM。
本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别。

参考资料：https://blog.csdn.net/qq_34827674/article/details/107678226?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link

**线程通信**

​	共享进程的资源，全局变量等方式实现线程之间的通信

#### （5）进程、线程、协程

进程：资源分配的基本单位，独立运行的基本单位，包括PCB、程序段和数据段，切换代价大（因为进程的切换回造成TLB会失效，需要保存很多寄存器的状态等）

线程：调度的基本单位，独立的寄存器组、指令计数器、处理器状态，与同一进程下线程共享地址空间，可以有内核态线程和用户态线程，用户态线程即协程。

协程：线程创建的执行体，只能分配用户栈，也称为”用户态线程”，思想关键在于控制流的主动让出和恢复，每个协程拥有自己的协程栈，可以保存自己的执行现场。

区别：

（1）从属关系，独立性，通信方式，相互之间

（2）进程同步方法：互斥锁、读写锁、条件变量、记录锁、信号量、屏障
		  线程同步方法：互斥锁、读写锁、条件变量、信号量、自旋锁、屏障

虚拟地址空间被划分为内核空间和用户空间。

**进程控制信息在内核空间中**，包括虚拟内存状态（如页目录）、进程ID、父进程ID、进程状态、打开文件句柄表，线程是进程中的执行体，要有指定的执行入口。 

**线程控制信息在内核空间中**，包括执行入口、线程栈（操作系统会分配两段栈--用户栈和内核栈，线程切换到内核态运行时会切换到内核栈，为了不允许用户代码对齐进行修改保护安全）、线程ID等。

当需要执行某个线程时，IP指向该线程的执行入口，栈基和栈指针寄存器会记录用户栈的位置【这意味着程序执行时CPU面向的是某个线程，所以说线程是操作系统调度和执行的基本单位】

一个进程中至少要有一个线程 -- 主线程，一般是有父进程或操作系统创建的，其他线程一般是由主线程创建的，线程发生函数调用时则在线程栈中分配函数调用栈，线程调用系统服务（虚拟内存分配、文件操作、网络读写等）时通过**系统调用**（最初是软中断--通过指令模拟中断，系统调用表+中断向量表，后来改为通过特殊指令触发 ，从专用寄存器拿派发入口地址，省去查询中断向量表的过程）来完成。

线程切换：保存当前线程执行现场如指令指针、栈指针等寄存器的值，修改为切换线程的寄存器值，内存中调度相关的数据结构

进程切换：CPU保存的页目录地址要修改为切换进程的页目录地址，会导致地址空间等进程资源发生变化，会导致TLB缓存失效

协程与IO多路复用：
IO多路复用会涉及到socket，而socket操作都由操作系统来提供，进程控制信息中会保存socket文件句柄，每个TCP socket创建时操作系统都会为其分配一个读缓冲区和写缓冲区（在内核空间中，需要完成拷贝到用户空间的操作）。
当出现没有数据可以读或者写缓冲区满时，怎么处理：
（1）阻塞式IO -- 让出CPU，进入等待队列，处理一个socket就要一个线程，在高并发场景下会加剧调度开销
（2）非阻塞式IO -- 不让出CPU，频繁检查socker是否就绪，容易造成空耗CPU，加剧延迟
（3）IO多路复用 -- 由操作系统提供支持，将需要等待的socket加入监听集合，通过一次系统调用，同时监听多个socket
		【1】select：每次都要传入所有监听集合，需要频繁从用户态到内核态拷贝数据，就绪时也需要遍历
		【2】poll： 监听数目等于可打开的文件符个数
		【3】epoll：分为水平触发和边缘触发模式。
（4）信号驱动：通知来取
（5）异步I/O：直接快递

总体来看 -- 就绪时需要恢复现场，陷入等待时需要保存现场   -> 协程很适合

#### （6）死锁

条件：互斥资源有限、不可抢占、占有并请求、循环等待

解决方案：

- （1）检测与恢复 -- 检查时资源分配矩阵，资源等待矩阵，系统当前可用总量；恢复时可采用抢占！杀死！回滚！
- （2）不让死锁发生
  - 避免死锁（动态）：银行家算法-- 在分配前确保资源分配后不会进入不安全状态（死锁或潜在死锁）
  - 消除必要条件（静态）：增加资源（破坏资源有限，不现实）、资源一次性分配（破坏保持并请求，资源利用率不高）、可抢占资源（破坏不可抢占）、资源有序分配（破坏循环等待，定义资源请求顺序）

#### （7）缓存穿透、缓存击穿、缓存雪崩

缓存穿透：缓存和数据库中都没有的数据，可能属于攻击，可以通过校验或缓存空值或布隆过滤器防范

缓存击穿：缓存中没有但数据库中有的数据，由于并发用户多且访问同一数据，同时缓存中没有读到，导致数据库压力瞬间增大，可以通过设置热点数据永不过期和互斥锁来防范

缓存雪崩：缓存中数据大批量到了过期时间，而查询数量巨大，引起数据库压力过大甚至宕机，可以通过设置随机过期时间+热点数据均匀分布+永不过期来防范

#### （8）进程调度

可以调度：

* 当前进程运行结束
* 当前进程阻塞
* 系统调用后返回用户进程
* 抢占式+高优先级
* 时间片耗尽

不可调度：

* 中断程序处理
* 内核程序临界区
* 屏蔽中断的原子操作过程中

调度策略：

FCFS、SJF、优先级调度、时间片轮转、高响应比、多级队列、多级反馈队列

#### （9）同步的本质

实现临界区操作的互斥性，单核状态下，借助硬件指令（Compare And Swap、Fecth And Add、Test And Set等）实现锁机制，但在多核状态下，仅依靠硬件指令是不够的，需要借助总线锁（一旦使用了总线锁，则从并行变成了串行），而当前的缓存机制使得为了保证多核间高速缓存的一致性，引入了MESI协议（高速缓存一致性协议）

#### （10） 进程创建

- 分配进程控制块
  - 进程基本信息指针（进程ID、创建用户ID、创建时间等）
  - 进程家族树指针（子进程、父进程、孙子进程、祖父进程）
  - 信号支持
  - 进程状态信息指针（程序寄存器、状态字、优先级等）
  - 时间统计信息（所占CPU时间、子进程所占CPU时间等）
  - 其他需要的信息指针...
- 初始化机器寄存器
- 初始化页表
- 将程序代码从磁盘读进内存
- 将处理器状态设置为“用户态”
- 跳转到程序的起始地址（设置程序计数器）

最后两步借助硬件作为一个原子步骤一起完成



#### （11）进程调度

- 因时序或外部中断或进程挂起导致系统获得CPU控制权
- 操作系统在所有就绪进程中按照某个算法遴选进程
- 如果选中的是非当前进程，则操作系统将当前进程状态予以保护
- 为选中的进程布置环境（寄存器、栈指针、状态字等）
- 跳转到选中的进程



#### （12） 线程资源

共享资源：地址空间、全局变量、打开的文件、子进程、计时器、信号和信号服务程序、记账信息

独享资源：程序计数器、寄存器、栈、状态字



#### （13） 锁机制 -- 线程同步

```c++
// 故事：Alice和Bob喂鱼，一天内只能且必须有一个人喂鱼，否则鱼会胀死或饿死
// ====  朴素思想，没喂则喂一次
// == alice
if (noFeed) {
  feed
}
// == bob
if (noFeed) {
  feed
}
// 【问题】：线程的执行顺序是未知的，所以鱼可能会胀死
// 引入互斥 -- 不能由两个进程同时进入临界区，进程能正确执行，互斥区域外不能阻止另一个进程的运行，不能无限等待
// ==== 互斥喂，通过交谈（留下纸条）
// == alice
if (noNote){
  leave note;
  if (noFeed){
    feed;
  }
  remove note
}
// == bob
if (noNote){
  leave note;
  if (noFeed){
    feed;
  }
  remove note
}
// 【问题】：线程的执行顺序是未知的，所以鱼还是可能会胀死，因为留下纸条并没有达到互斥的目的（先检查再留字条），但降低了胀死的概率
// 防止同时进入临界区 -- 先留自己的字条，再检查对方的字条
// == alice
leave noteAlice;
if (noNoteBob){
  if (noFeed){
    feed;
  }
  remove note
}
// == bob
leave noteBob;
if (noNoteAlice){
  if (noFeed){
    feed;
  }
  remove note
}
// 【问题】：两个可能都留了纸条但还没来得及喂鱼，此时存在鱼会饿死的可能性
// ==== 确认有人喂了鱼才离去
// == alice
leave noteAlice;
while (noNoteBob){
  do nothing;
}
if (noFeed){
   feed;
}
remove note;
// == bob
leave noteBob;
if (noNoteAlice){
  if (noFeed){
    feed;
  }
}
remove note;
// 【问题】：程序不对称+CPU浪费
// ==== 借助锁
// == alice
lock(); // 等待锁打开，获得锁并锁上
if (noFeed){
    feed;
}
unlock(); // 打开锁
// == bob
lock();
if (noFeed){
    feed;
}
unlock();
// 【问题】：等待的人会一直在做无效等待
// ==== 减小临界区代码
// == alice
lock(); // 等待锁打开，获得锁并锁上
if (noNoteBob)
  leave noteAlice
unlock();
if (noNoteBob){
  if (noFeed){
    feed;
	}
}

// == bob
lock(); // 等待锁打开，获得锁并锁上
if (noteAlice)
  leave noNoteBob
unlock();
if (noNoteAlice){
  if (noFeed){
    feed;
	}
}
// 【问题】还是会有忙等的时间，借助sleep和wake up
// 引入生产者-消费者问题
// 解决两个问题：
// （1）检查count时唤醒对方，可能没有sleep的对方
// （2）对count变量的修改可能会发生数据竞争
// 引入信号量：叫醒信号保留，将信号积累起来操作系统原语
// 三个信号量：一个二元信号量用于互斥，另两个信号量分别用于唤醒对方
const int N=100;
typedef int semaphore;
semaphre mutex=1;
semaphore empty=N;
semaphore full=0;
void producer() {
  int item;
  while(True){
    item=produce_item();
    down(empty);
    down(mutex);
    insert_item(item);
    up(mutex);
    up(full);
  }
}
void consumer() {
  int item;
  while(True){
    down(full);
    down(mutex);
    remove_item(item);
    up(mutex);
    up(empty);
  }
}
// 【问题】：如果将两个down颠倒，会产生死锁，颠倒两个up不会改变正确性，但会导致程序效率下降
// 引入管程 = 锁 + 条件变量（线程可以在上面等待的东西，另一个线程可以发送信号将在条件变量上的线程唤醒）
// 中心思想：在管程内睡觉的线程，睡前将进入管程的锁或信号量释放。
// 管程的问题：对编译器的依赖；网络环境下进行同步需要引入其他机制 -- 消息传递
// 消息传递是通过 同步双方经过互相发送消息来实现，有两个系统调用（可以是阻塞调用也可以是非阻塞调用），同步需要的是阻塞调用。
```

原子操作：不可被中断的一个或多个系列操作
每个CAS操作过程包含三个量：内存地址、期望值、新值
基本思路：如果地址上的值和期望值相等，则给其赋予新值，否则不做任何事情，而只返回原值是多少
处理器实现：总线加锁/缓存加锁/

#### （14）文件系统

| 主引导记录 | 分区表 | 分区1（主分区） | 分区2 | 分区3 | ...  | 分区n |
| :--------: | :----: | :-------------: | :---: | :---: | :--: | :---: |

​                                    										          	/															\	

| 引导记录 | 超级数据块 | 闲置空间管理 | I-NODE区 | 根目录区 | 文件和目录区 |
| :------: | :------: | :------: | :------: | :------: | :------: |

一个磁盘包括一个个扇面，从0开始编号，0号扇面存放的是主引导记录（MBR）【一个小小的程序，用来启动计算机】，紧跟着磁盘分区表（磁盘的所有分区及其开始和结束地址）【其中一个分区为主分区，操作系统装载在此分区，主分区中最前面的是引导记录（Boot Record）】，在引导记录块后的内容因情况而异，一般是一个超级数据块（Super Block）【存放文件系统的各种参数如文件新系统类型、文件系统数据块尺寸等】，在超级数据块之后则是磁盘自由空间，后面是I-NODE区，再往后是文件系统根目录区，分区最后存放的是用户文件和文件夹区。

**引导记录**：一个小程序，负责找到操作系统映像，并加载到内存，从而启动操作系统

计算机启动时，主板ROM中的BIOS程序首先运行，进行基本的系统配置扫描后对磁盘的0号扇面进行读操作，将主引导记录（MBR）中的程序读入内存并运行，MBR程序接下来找到主分区，并将主分区里面的引导记录加载并运行。



文件的数据结构中有一个存放文件数据指针的表（文件分配表）

索引文件组织：将所有文件的所有数据块的磁盘地址收集起来，集中放在一个索引数据块里，文件打开时将该数据块加载到内存。即I-NODE（文件的逻辑数据块号 -- 对应的物理磁盘数据块编号）



Linux中会为每个文件分配两个数据结构：索引节点和目录项，主要用于记录文件的元信息和目录层次结构。

- 索引节点：即inode，用于记录文件元信息如inode编号、文件大小、访问权限、创建时间、修改时间、磁盘位置等，是文件的唯一标识。
- 目录项：即dentry，用来记录文件名、索引节点指针以及其他目录项的层级关系。多个目录项关联起来形成目录结构，目录项是由内核维护的维护的数据结构，不存放于磁盘，而是缓存于内存。

索引节点唯一标识一个文件，而目录项记录文件名，所以目录项与索引节点是多对一的关系即一个文件可以有多个别名【硬链接实现就是多个目录项的索引节点指向同一个文件】

目录也是文件，也是用索引节点唯一标识，和普通文件的区别是目录文件在磁盘中保存子目录或文件，而普通文件在磁盘中保存的是文件数据。



硬盘格式化时会被分为三个存储区域

- 超级块

  存储文件系统的详细信息如块大小、块个数、空闲块等

  当文件系统挂载时进入内存

- 索引节点区

  存储索引节

  当文件被访问时进入内存

- 数据块区

  存储文件或目录数据



#### （15）虚拟内存 vs 文件缓存

一部分程序（文件）处于内存、一部分程序（文件）处于磁盘

虚拟内存的根本目的：提供一个速度非常快、容量非常大的并不存在的内存空间，从物理内存出发，为了增加内存空间而扩展到磁盘上。

文件缓存的根本目的：提高文件的访问效率，从磁盘出发，为了提高访问效率而将文件置于缓存



#### （16） DHCP

基于UDP，主要过程：

- 客户端广播DHCP Discover报文（服务器的IP地址对于客户端来说是未知的，所以用广播）
- 所有的DHCP服务器回应DHCP Offer报文（此时客户端知道服务器的IP了，其中也提供了一个合适的IP及租约、网关等配置信息，在选择合适IP时，会确认锁分配的IP没有被其他设备所使用，通过ICMP报文进行探测数次，如果都没有收到应答则说明IP可用）
- 客户端广播DHCP Request报文（一般针对第一个Offer报文，采用广播的原因是通知所有的DHCP服务器客户端的选择，以让其他服务器收回曾提供的IP）
- 服务器回应DHCP ACK报文（根据MAC地址查询有没有租约记录，如果有则发送ACK报文，在客户端收到ACK后，广播发送ARP报文探测是否有主机使用服务器分配的IP地址，否则发送DECLINE报文给服务器，通知服务器提供的IP地址不可用，并重新申请；否则发送NAK报文作为应答以告知无法分配合适的IP地址，此时客户端重新申请）
- 租约到期时，客户端发送DHCP Release报文释放IP地址



#### （17）边际网关协议BGP vs 开放式最短路径优先协议（OSPF）

BGP：实现自治系统（AS）之间路由可达，并选择最佳路由的距离矢量路由协议

OSPF：内部网关协议，单一自治系统内决策路由



#### （18）向操作系统申请内存

涉及两个系统调用：brk和mmap

brk: 将进程数据段的最高地址指针向高处移动，可以扩大进程在运行时的堆大小

mmap:将进程虚拟空间中寻找一块空闲的虚拟内存，获得一块可以操作的堆内存

其中brk用于分配小于128k的内存，mmap用于申请大于128k的内存

进程先通过系统调用获取或扩大进程的虚拟内存，获取虚拟地址

直到访问这些虚拟地址时产生缺页中断，分配物理页，内存分配才算完成



#### （18） 信号 vs 中断

信号：每个信号对应一个正整数常量，代表同一用户的诸多进程之间传送事先约定的信息类型，用于通知某进程发生了某异常事件。每个进程在运行时都要通过信号机制来检查是否有信号到达，若有则中断当前程序，转去处理该信号对应的处理程序，以完成对该事件的处理，处理结束后再返回到原来的断点继续执行。

二者相似点：

- 相同的异步通信方式，检测到信号或中断请求时都暂停当前程序，转去处理相应的处理程序，并在处理完毕后返回原来的断点
- 都可以对信号、中断进行屏蔽

二者不同点：

- 中断具有优先级，而信号平等
- 信号处理程序是在用户态下运行的，而中断处理程序是在内核态运行 
- 中断响应是及时的，而信号响应通常有较大时间延迟

信号机制的用途/功能：

- 发送信号，使用系统调用kill实现
- 预置对信号的处理方式，接受信号的程序用signal()来实现对处理方式的预置
- 接受信号的程序按事先的规定完成相应事件的处理



#### （19）一个进程能创建多少线程？

- 系统位数（32or64）下的用户空间大小和创建线程分配的栈空间大小

- 内核参数
  - /proc/sys/kernel/threads-max，系统支持的最大线程数，默认14553
  - /proc/sys/kernel/pid_max，系统全局PID号数值限制，默认32768
  - /proc/sys/vm/max_map_count，限制一个进程可以拥有的VMA（虚拟内存区域）的数量，默认65530



#### （20） CPU缓存一致性

在不同核上的两个线程对同一个变量进行操作，由于缓存策略的问题，某一个线程修改了变量但并未写会内存，此时另一个线程尝试从内存中读取，导致执行结果错误，这就是所谓缓存一致性问题。

解决机制：

- 某个核上对Cache数据的更新，**必须**传播到其他核心的Cache，称之为**写传播**
- 某个核上对数据的操作顺序，**必须**在其他核看来顺序是一样的，称之为**事务的串形化**【解释：由于不同核对数据进行同时修改，进行写传播时由于随机性的结果导致收到的顺序不一样，进而导致其他核上缓存中数据不一致】
  - 核对于Cache中数据的操作，需要同步给其他核
  - 引入锁机制，只有拿到锁才能更新

通过**总线嗅探**等方式将更新传递给其他核，此时每个核都要监听总线上的一切活动而不管其他核是否缓存了相同数据，而且并未实现事务串形化。

**MESI**协议做到了CPU缓存一致性。

**MESI协议** ： Modified（已修改）、Exclusive（独占）、Shared（共享）、Invalidated（已失效）标记缓存块的不同状态，其中独占核共享状态表示缓存块中数据时一致的，差别在于独占状态下数据只存储在一个核心的缓存中，可以自由写入，但如果其他核从内存中读取了相同的数据，则独占状态下的数据就会变为共享状态；共享状态下的缓存中数据更新时不能直接修改，而是先向其他核广播请求--将对应的缓存行标记为无效状态，然后再更新当前核缓存中的数据。



#### （21）Cache伪共享

指两个核上的不同线程对同一个内存块进行缓存，但修改的数据不冲突（线程1修改A，线程2修改B），由于写回策略的问题，会持续交替分别修改相应变量，在MESI协议下，缓存也会持续交替失效的现象。

解决方案：

- Linux 内核中 `__cacheline_aligned_in_smp`宏定义用于解决伪共享问题，实质上将不同的变量进行“缓存块级别的对齐“
- Java并发框架Disruptor使用【字节填充+继承】的方式避免伪共享问题



#### （22）忙等锁（自旋锁）/无忙等锁的基本实现

忙等锁/自旋锁

```c++
typedef struct lock_t{
  int flag;
}lock_t;
void init(lock_t *lock){
  lock->flag=0;
}
void lock(lock_t *lock){
  while(TestAndSet(&lock->flag,1)==1){
    // do nothing
  }
}
void unlock(lock_t *lock){
  lock->flag=0;
}
```

无忙等锁

```c++
typedef struct lock_t{
  int flag;
  queue_t *q; // 等待队列
}lock_t;
void init(lock_t *lock){
  lock->flag=0;
  queue_init(lokc->q);
}
void lock(lock_t *lock){
  while(TestAndSet(&lock->flag,1) == 1){
    // 保存当前线程TCB
    // 将当前线程TCB插入等待队列
    // 设置当前线程为等待状态
    // 执行调度程序
  }
}
void unlock(lock_t *lock){
  if(lock->q !=Null ){
    // 移出等待队列队首元素
    // 将该线程的TCB插入就绪队列
    // 设置该线程为就绪状态
  }
  lock->flag=0;
}
```



#### （23）读者-写者问题

- 读者优先，写者可能处于饥饿状态

  ```c++
  semaphore wMutex; // 初始值为1，控制写操作的互斥信号量
  semaphore rCountMutex; // 初始值为1，控制rCount的修改
  int rCount = 0; // 初始值为0
  void writer(){
    while(TRUE){
      P(wMutex);
      write();
      V(wMutex);
    }
  }
  void reader(){
    while(TRUE){
      P(rCountMutex);
      if (rCount == 0) {
        P(wMutex); // 阻塞写者
      }
      rCount++;
      V(rCountMutex);
      
      read();
      
      P(rCountMutex);
      rCount--;
      // 最后一个读者离开，唤醒写者
      if ( rCount  == 0 ){
        V(wMutex);
      }
      V(rCountMutex);
    }
  }
  
  ```

- 写者优先，只要有写者准备写入，则后来的读者要阻塞，当然，读者可能会饥饿

  ```c++
  semaphore rCountMutex; // 初始值为1，控制rCount的修改
  semaphore rMutex; // 初始值为1，控制读者进入的互斥信号量
  
  semaphore wCountMutex; // 初始值为1，控制wCount的修改
  semaphore wDataMutex; // 初始值为1，空着写着写操作的互斥信号量
  
  int rCount=0;
  int wCount=0;
  
  void writer(){
    while(TRUE){
      P(wCountMutex);
      if (wCount ==0 ){
        P(rMutex); //阻塞读者
      }
      wCount++;
      V(wCountMutex);
      
      P(wDataMutex);
      write();
      V(wDataMutex);
      
      P(wCountMutex);
      wCount--;
      if (wCount == 0){
        V(rMutex); //最后一个写者离开，唤醒读者
      }
      V(wCountMutex);
    }
  }
  void reader(){
    while(TRUE){
      P(rMutex);
      P(rCountMutex);
      if (rCount == 0){
        P(wDataMutex); // 阻塞写者
      }
      rCount++;
      V(rCountMutex);
      V(rMutex);
      
      read();
      
      P(rCountMutex);
      rCount--;
      if (rCount == 0){
        V(wDataMutex); // 最后一个读者离开，唤醒写者
      }
      V(rCountMutex);
    }
  }
  ```

- 公平策略

  ```c++
  semaphore rCountMutex; // 初始值为1，控制rCount修改
  semaphore wDataMutex; // 初始值为1，控制写者写操作
  semaphore flag; // 初始值为1，用于实现公平竞争
  int rCount = 0;
  void writer(){
    while(TRUE){
      P(flag); // 不让后来的读者直接进入，而是在那里等待以实现公平
      P(wDataMutex);
      write();
      V(wDataMutex);
      V(flag);
    }
  }
  void reader(){
    while(TRUE){
      P(flag);
      P(rCountMutex);
      if (rCount == 0){
        P(wDataMutex);
      }
      rCount++;
      V(rCountMutex);
      V(flag);
      
      read();
      
      P(rCountMutex);
      rCount--;
      if (rCount == 0){
        V(wDataMutex);
      }
      V(rCountMutex);
    }
  }
  ```

#### （24）锁

如果能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该用自旋锁。反之则应该用互斥锁。

- 互斥锁

  最底层的锁之一，加锁失败后，线程释放CPU，会从用户态陷入内核态，**由操作系统内核实现**

- 自旋锁

  最底层的锁之一，加锁失败后，会忙等，直到拿到CPU，**通过CPU提供的CAS原子操作，在用户态完成加锁和解锁操作**，不会主动产生线程上下文切换。

  最好使用CPU提供的PAUSE指令来实现忙等待，可以减少循环等待时的耗电量。

  **单核下需要抢占式的调度器，否则自旋锁在单CPU无法使用，因为一个自旋的线程永远不会放弃CPU。**

- 读写锁

  由读锁和写锁两部分组成，如果只读取则用读锁加锁，如果修改共享资源则用写锁加锁。适用于能明确区分读操作和写操作的场景。

  工作原理：

  - 没有线程拥有写锁时，多个线程可以并发地持有读锁，大大提高了共享资源的访问效率。
  - 一旦有线程拥有写锁，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。
  
  根据实现的不同，可以分为读优先锁和写优先锁。

  - 读优先锁：当读线程A先持有了读锁，写线程B在获取写锁时，会被阻塞，并在阻塞过程中，读线程C可以成功获取读锁，直到所有的读线程都释放读锁后，写线程B才能获取写锁。
  - 写优先锁：当读线程A先持有了读锁，写线程B在获取写锁时，会被阻塞，并在阻塞过程中，读线程C获取读锁时会失败，于是读线程C将被阻塞在获取读锁的操作，只有当读线程A释放读锁后，写线程B才能成功获取写锁。
  - 公平读写锁：用队列把获取锁的线程排队，不管是写线程还是读线程，都按照先进先出的原则加锁即可，这样读线程仍旧可以并发也不会出现饥饿。
  
- 悲观锁

  认为多线程同时修改共享资源的概率比较高，容易出现冲突，

  工作方式：访问共享资源前，先要上锁。

- 乐观锁

  假定多线程同时修改共享资源的概率比较低，冲突的概率低。

  工作方式：先修改共享资源，再验证这段时间内有没有发生冲突，如果没有则操作完成，否则放弃本次操作。

  缺点是一旦发生冲突，重试的成本非常高，所以一般只有在冲突概率非常低，且加锁成本非常高的场景中才考虑使用。
  
  CAS是一种乐观锁技术。当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。CAS是一种非阻塞式的同步方式。
  
  CAS会导致ABA问题，可以通过对变量加上版本号的方式来解决ABA问题。

​	

#### （25） 硬链接 vs 软链接

硬链接：多个目录项的索引节点指向一个文件（同一个inode），但不可跨文件系统（因为每个文件系统都有各自的inode数据结构和列表），只有删除所有的硬链接及源文件，系统才删除。

软链接：特殊的文件，有独立的inode，文件内容是另一个文件的路径，可以跨文件系统，甚至目标文件被删除了，链接文件还是在的。



#### （26）缓冲/非缓冲 I/O vs 直接/非直接 I/O vs 阻塞/非阻塞 I/O vs 同步/异步 I/O

缓冲I/O：利用标准库的缓存实现文件的加速访问，而标准库再通过系统调用访问文件

非缓冲I/O：直接通过系统调用访问文件，不经过标准库缓存

直接I/O：不发生内核缓存和用户程序之间的数据复制，而是直接通过文件系统访问磁盘。需要在使用文件系统类系统调用时指定`O_DIRECT`标志位。

非直接I/O：读操作时，数据从内核缓存中拷贝给应用程序，写操作时，数据从用户程序拷贝给内核缓存，再有内核决定什么时候写入数据到磁盘。文件系统类的系统调用的默认设置。

阻塞I/O：当用户程序执行read时，线程被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序缓冲区，拷贝完成时，read才会返回。【等待着**内核准备好数据**和**数据从内核态拷贝到用户态**】。访问管道或socket时的默认行为。

![clipboard.png](https://segmentfault.com/img/bVm1c3)

非阻塞式I/O：非阻塞的read请求在数据未准备好时立即返回，可以继续往下执行，此时应用程序**不断轮询内核，直到数据准备好，内核将数据拷贝到应用缓冲区，read调用才返回结果。**【等待着**内核态数据拷贝到用户态**】。访问管道或socket时需要设置`O_NONBLOCK`标志位。

![clipboard.png](https://segmentfault.com/img/bVm1c4)

为了解决“傻乎乎”的轮询方式，引入了**I/O多路复用**：通过I/O事件分发，当内核数据准备好时再通知应用程序进行操作。select/poll的优势不是对于单个连接的处理更快而是能同时处理多个连接。

- select：阻塞系统调用，直到数据准备好，然后通知用户进程数据可读，再由用户进程发出read系统调用，等待数据拷贝完成，再通知用户进程处理数据。

  ```c++
  int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
  ```

  

  ![clipboard.png](https://segmentfault.com/img/bVm1c5)

  通过设置或检查存放的fd标志位的数据结构来进行处理，但单个进程可监视的fd数目是有限的（一般与系统内存有关，/proc/sys/fs/file-namx查看，32位下默认1024，64位下默认2048），采用的扫描方式是线性扫描，时间复杂度为O(n)。

  每次调用select，都需要将fd集合从用户态拷贝到内核态，同时也需要在内核态中遍历（扫描）传递进来的fd，在fd很多时开销会很大。并且需要一个用来存放大量fd的数据结构，这个结构在从用户态到内核态传递也会有复制开销。

- poll：本质上与select没有区别，将用户传入的fd数组拷贝到内核，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有的fd没有发现就绪设备，则挂起当前进程，直到超时或设备就绪。

  ```c++
  int poll (struct pollfd *fds, unsigned int nfds, int timeout);
  struct pollfd {
      int fd; /* file descriptor */
      short events; /* requested events to watch */
      short revents; /* returned events witnessed */
  };
  ```

  因为基于链表的存储而解决最大连接数限制的问题。但因为每次被唤醒都要遍历所有的fd，同时大量的fd的数组要在内核态和用户态之间拷贝。

  还有一个特点是”水平触发“，报告了fd后，没有被处理，下次poll时会再次报告该fd。

- epoll：可以理解为event poll，不同于忙轮询和无差别轮询，会将**哪个流发生了怎么样的I/O事件通知**（每个事件上关联fd），复杂度降低为O(1)。

  有EPOLL LT（水平触发）和EPOLL ET（边缘触发）两种触发模式，LT是默认触发模式，只要这个fd还有数据可读，每次epoll_wait都会返回它的事件，提醒用户程序操作。但在ET模式下，只会提示一次，直到下次再有数据流入之前都不会再提示。

  **要有EPOLL ET的原因**：系统中一旦有大量不需要读写的就绪文件描述符，每次调用epoll_wait都会成功，大大降低处理程序检索自己关系的就绪文件描符的效率。而在ET模式下，如果被监控的文件描述符上有可读写事件发生，epoll_wait会通知处理程序去读写，如果这次没有全部处理完，下次epoll_wait也不会通知，效率高！

  只会管“活跃”的连接而无关连接总数，所以效率较select和poll都要高，同时利用mmap文件映射加速与内核空间的消息传递，减少了复制开销。理论支持的fd上限是最大可以打开文件的数目。

  提供三个函数：

  ```C++
  int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大
  int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；// 注册文件描述符，一旦基于某个文件描述符就绪时，内核会采用callback的方式迅速激活该文件描述符，当进程调用epoll_wait时就会收到通知
  int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
  ```

  - epoll_create：创建一个epoll句柄
  - epoll_ctl：注册要监听的事件类型，每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD）会把所有的fd拷贝进内核，而不是在epoll_wait时重复拷贝，保证每个fd在整个过程中只会拷贝一次。在epoll_ctl时把current挂一遍并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者是就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪列表
  - epoll_wait：等待事件的发生，在就绪列表中查看有没有就绪的fd，利用schedule_timeout实现睡一会判断一会的效果

在连接数少并且连接十分活跃的情况下，select和poll的性能可能比epoll要好（回调函数）。

同步I/O：阻塞I/O、非阻塞I/O、基于非阻塞I/O的多路复用

异步I/O：内核数据准备好、数据从内核态拷贝到用户态这两个过程都不用等待。aio_read之后立即返回，内核自动将数据从内核空间拷贝到应用程序空间，这个拷贝过程同样异步，由内核自动完成而无需应用程序主动发起拷贝动作。

![clipboard.png](https://segmentfault.com/img/bVm1c8)



参考资料：https://www.cnblogs.com/Anker/archive/2013/08/14/3258674.html

#### （27）文件描述符

在形式上是一个非负整数，实际山是一个索引值，**指向内核为每一个进程所维护的该进程打开的文件的记录表中的某一个记录**。

之所以使用文件描述符而非直接指向文件系统中的某个文件，是因为文件结构可能根据不同文件系统而发生变化，提供单一抽象有利于操作系统统一管理。

当程序打开或创建一个文件时，内核向该进程返回一个文件描述符。



#### （28）中断

软中断：代码调用INT指令等触发的中断

硬中断：硬件通过中断控制器触发的中断

设备驱动程序中会及时响应控制器发来的中断请求，并根据中断类型调用响应的中断处理程序（设备驱动程序初始化时注册该设备的中断处理函数）



#### （29）一个应用程序对外发送一个文件至少需要拷贝多少次？

- 应用程序调用socket发送数据包接口，首先通过read系统调用读取文件，从磁盘到磁盘缓冲区，需要发生一次拷贝，如果采用直接I/O，此处不需要拷贝，如果采用非直接I/O，则此处要发生一次内核态与用户态的数据拷贝；然后socket层会将应用层数据拷贝到内核的socket发送缓冲区中，此处要发生一次拷贝。
- 网络协议栈从socket发送缓冲区中取出数据包，按照协议栈从上往下处理，分片号的网络包送至网络接口层，再放到发包队列中
- 网卡驱动程序通过DMA从发包队列读取网络包，将其放入网卡的队列中，此处发生一次拷贝，然后网卡将其发送出去。

中间经过转发等过程

- 网络包达到目的端，网卡发起硬件中断，执行网卡硬件中断处理喊出，从网卡队列（Ring buffer）中拷贝到内核struct sk_buff缓冲区中，然后按照网络协议栈逐层处理，在传输层确定socket，并将数据拷贝到socket的接收缓冲区
- 应用程序通过调用socket接口，从内核的socket接受缓冲区读取数据到应用层
- 应用程序对数据进行处理，将文件存放至磁盘上，如果采用直接I/O，则不需要拷贝，如果采用非直接I/O，则要发生一次用户态到内核态到拷贝，再由内核决定什么时候将数据写入磁盘，写入磁盘也会发生一次拷贝。

此处的分析并未考虑CPU Cache！

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201009161615375.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAzODMzMg==,size_16,color_FFFFFF,t_70#pic_center)

引入DMA后

![截屏2021-10-13 12.46.34](/Users/ouyangshiyong/Library/Application Support/typora-user-images/截屏2021-10-13 12.46.34.png)

传统的文件传输方式：

![截屏2021-10-13 12.48.23](/Users/ouyangshiyong/Library/Application Support/typora-user-images/截屏2021-10-13 12.48.23.png)

期间发生了4次用户态与内核态的上下文切换，一次read，一次write。

期间发生了4次数据拷贝，其中2次是DMA拷贝，2次是CPU拷贝。

其中：从内核读缓冲区拷贝到用户缓冲区，再从用户缓冲区拷贝到socket的缓冲区即两次CPU拷贝是没有必要的，因此用户缓冲区可以省去。

再者，可以通过【零拷贝技术】减少上下文切换和数据拷贝次数。

【零拷贝技术】的实现方式：

- mmap+write

  使用mmap替换read，直接把内核缓冲区里的数据映射到用户间

  ![截屏2021-10-13 12.53.42](/Users/ouyangshiyong/Library/Application Support/typora-user-images/截屏2021-10-13 12.53.42.png)

  此时需要4次上下文切换（因为系统调用还是2次），3次拷贝。

- sendfile

  专门发送文件的系统调用，函数原型如下

  ```c++
  #include<sys/socket.h>
  // out_fd 目的端文件描述符
  // in_fd 源端文件描述符
  // offset 源端偏移量
  // count 复制数据的长度
  // 返回值是实际复制的长度
  ssize_t sendfile(int out_fd,int in_fd,off_t *offset,size_t count);
  ```

  首先，可以用该系统调用代替read和write两个系统调用，减少1次系统调用则减少2次上下文切换

  其次，sendfile可以直接将内核缓冲区的数据拷贝到socket缓冲区中，不再拷贝到用户态，共3次拷贝

  ![截屏2021-10-13 12.58.20](/Users/ouyangshiyong/Library/Application Support/typora-user-images/截屏2021-10-13 12.58.20.png)

如果网卡支持SG-DMA技术（与普通的DMA不同），可以进一步减少通过CPU把内核缓冲区的数据拷贝到socket缓冲区过程，此时sendfile系统调用将使用如下过程：

- 通过DMA将磁盘上数据拷贝到内核缓冲区中
- 缓冲区描述符和数据长度传到socket缓冲区，网卡的SG-DMA控制器直接将内核缓冲区的数据拷贝到网卡缓冲区中

![截屏2021-10-20 13.02.43](/Users/ouyangshiyong/Library/Application Support/typora-user-images/截屏2021-10-20 13.02.43.png)

CPU不参与数据搬运，所有数据都由DMA完成。只需要2次上下文切换和2次数据拷贝，并且这2次数据拷贝不需要通过CPU而是通过DMA搬运完成。性能提升至少一倍。

**Kafka开源项目利用了零拷贝从而大幅提高了I/O效率，Nginx也支持零拷贝技术**

下面解释一下上面提到的【内核缓冲区】，实际上是磁盘高速缓存（PageCache），利用程序运行的局部性原理，使用PageCache缓存最近被访问的数据，读磁盘数据时，优先在PageCache中找，其次再从磁盘中读取。同时了为了降低机械硬盘的物理消耗时间，使用【预读】功能（利用的是空间局部性），**但是在传输大文件（GB级）时，PageCache会不起作用，会浪费【预读】的一次DMA，造成性能降低。**

针对大文件传输，不应该使用PageCache，也就是说不应该使用零拷贝技术，因为此时磁盘缓冲区持续失效，性能急剧下降，而且大文件将占据缓冲区，导致热点小文件无法使用，在高并发环境下，可能形成灾难。
大文件传输应该通过异步I/O，因为它并未涉及PageCache（绕过PageCache的I/O其实就是直接I/O，使用PageCache的I/O则就是缓存I/O），传统的中断方式流程如下：

![截屏2021-10-20 13.06.49](/Users/ouyangshiyong/Library/Application Support/typora-user-images/截屏2021-10-20 13.06.49.png)使用异步IO方式解决阻塞问题：

![截屏2021-10-13 13.07.43](/Users/ouyangshiyong/Library/Application Support/typora-user-images/截屏2021-10-13 13.07.43.png)



#### （30）Socket为什么要绑定IP地址和端口？

- 绑定端口：当内核收到报文，通过报文的端口号来找到响应的应用程序
- 绑定IP地址：同一台机器上可以有多张网卡，每个网卡都有对应的IP地址，绑定IP后，内核收到对应网卡的包才会转发给用户态处理。

在内核中socket以文件形式存在，有对应的文件描述符。

每⼀个进程都有⼀个数据结构 task_struct ，该结构体⾥有⼀个指向「⽂件描述符数组」的成员指针。该数组⾥列出这个进程打开的所有⽂件的⽂件描述符。数组的下标是⽂件描述符，实质上是⼀个整数，⽽数组的内容是⼀个指针，指向内核中所有打开的⽂件的列表，也就是说内核可以通过⽂件描述符找到对应打开的⽂件。每个文件都有一个inode，socket文件的inode指向内核中的socket结构，其中有发送队列和接收队列，队列中保存的是一个一个strcut sk_buff，用链表进行管理。sk_buff可以表示各层数据包，应用层叫data，tcp层叫segment，ip层叫packet，数据链路层叫frame。只用一个结构体描述的原因是省去协议栈分层下解析数据带来的数据拷贝，而是通过指针逐步剥离/填充协议首部。



#### （31）网络I/O模型

为了服务更多的用户！

多进程模型 -> 多线程模型->线程池的多线程模型

I/O多路复用下的线程池多线程模型：一个进程维护多个socket



#### （32）POSIX接口

通常是通过C Library（libc）实现的，常见的libc有glibc、musl、eglibc等，Android实现了名为bionic的libc。

应用程序只需要通过调用libc提供的接口就可以实现对操作系统功能的调用，同时也实现了在类UNIX系统上的可移植性。

不同操作系统也可以通过对libc的移植来支持现有的应用生态。

在POSIX或操作系统系统调用的基础上，可以封装面向不同领域的领域应用接口（定义应用开发接口与软件架构）。

API指应用程序编程接口，定义了两层软件（如libc与Linux内核）之间源码层面的交互接口。
ABI指应用二进制接口，即在某个特定体系结构下两层软件之间的二进制层面的交互接口，包括如何定义二进制文件格式（如ELFhuoEXE）、应用程序之间的调用约定（参数和返回值处理）、数据模式（大端/小端模式）等



#### （33）指令集架构（ISA）

包括指令集、特权级、寄存器、执行模式、安全扩展、性能加速扩展等多个方面。

- 指令集，通常包含一系列不同功能的指令，用于数据移动、计算、内存访问、过程调用等。CPU在运行操作系统或应用程序时，实际上是在执行被编译后的所包含的指令。以AArch64（Armv8的两种模式之一，支持64位虚拟地址）为例，每条指令的长度固定为4字节，包括以下类型

  - 数据移动指令（如mov）
  - 寄存器计算指令（如add、sub）
  - 内存读写指令（如ldr、str）
  - 跳转指令（如无条件跳转指令b）
  - 过程调用指令（如调用指令bl、返回指令ret）
  - 特权指令（如读取操作系统寄存器指令msr、写入操作系统寄存器指令mrs）

- 特权级，在AArch64中被称为异常级别（Exception Level），共4种特权级。

  - EL0:最低特权级别，应用程序通常运行在此级别，称为用户态
  - EL1:操作系统通常运行在此级别，称为内核态
  - EL2:虚拟化场景下，虚拟机监控器（VMM or Hypervisor）通常运行在此级别
  - EL3:和安全特性TrustZone相关，负责普通世界和安全世界之间的切换

  CPU特权级从EL0切换到EL1的常见切换场景：

  - 系统调用，同步的CPU特权级切换，通过执行svc（特权调用，supervisor call）指令将CPU特权级从EL0切换到EL1
  - 触发异常，同步的CPU特权级别切换，导致，如应用执行访存指令时触发缺页异常
  - 中断，异步的CPU特权级别切换，如CPU收到来自外设的中断，也可以让一个CPU核心去通知另一个CPU核心。

  发生特权级别切换时，CPU保存**当前执行状态**，以便操作系统内核在处理异常时使用并在处理结束后能够恢复应用程序的执行。当前执行状态主要包括：

  - 触发异常的指令地址（即程序计数器PC）保存在ELR_EL1（异常链接寄存器）中
  - 异常原因（异常是由于svc指令还是由于访存缺页导致的）保存在ESR_EL1（异常症状寄存器）中
  - CPU将栈指针（SP）从SP_EL0（应用程序使用的栈）切换到SP_EL1（操作系统可以通过设置这个寄存器来配置异常处理过程中使用的栈）
  - CPU还会保存一些状态，如CPU相关的状态保存到SPSR_EL1（已保存到程序状态寄存器）中，将引发缺页异常的地址保存在FAR_EL1（错误地址寄存器）中

  操作系统在异常向量表中为不同的异常类型配置相应的异常处理函数，在特权级别切换时，CPU会读取VBAR_EL1（向量基址寄存器）来获取异常向量表的基地址，然后根据异常原因（ESR_EL1中保存的内容）调用操作系统设置的异常处理函数，之后，执行相应的异常处理函数，该函数一般会保存应用程序的上下文（如通用寄存器），然后根据异常原因进行响应的处理，异常处理完成后，操作系统会恢复应用程序的上下文，执行eret（异常返回）指令以恢复CPU自动保存的EL0状态（包括PC和SP等）并切换回EL0，使应用程序从中断处继续执行。

- 寄存器，在AArch64中，有31个64位通用寄存器（命名为X0-X31），其中，X29用作帧指针（Frame Pointer）寄存器（一般用于保存函数调用过程中栈顶的地址），X30用作链接指针（Link Pointer）寄存器（CPU在执行函数调用指令bl时会自动把返回地址保存在其中）。EL1特权级下有两个页表基地址寄存器（TTBR0_EL1和TTBR1_EL1），负责翻译虚拟地址空间中不同的地址段，负责的地址范围由另一个控制寄存器TCR_EL1（翻译控制寄存器）决定。另一种常见配置时TTBR0_EL1负责`[0,2^48)`的地址映射，TTBR1_EL1负责`[2^48,2^64)`的地址映射。



#### （34）内存映射输入输出（MMIO）

把输入输出设备和物理内存放到同一个地址空间，为设备内部的内存和寄存器也分配相应的地址，可以使用和访问物理内存一样的指令去读写设备和操作设备。而设备通过监听总线CPU分配给自己的地址，然后完成相应请求。

但CPU如何知道有输入事件发生了？

- 轮询，不断去通过MMIO查看是否有输入
- 中断，赋予设备通知CPU的能力，通过中断打断CPU的执行，使得CPU处理中断。

#### （35）Linux中进程控制块（PCB）与线程控制块（TCB）

**进程控制块（PCB）**包括进程状态、虚拟内存状态、进程标识符、进程组标识符、进程间关系、父进程信息、子进程信息、打开的文件、其他状态（如上下文）

进程的上下文包括进程运行时的寄存器状态，其能够用于保存和恢复一个进程在处理器上运行的状态

**上下文切换会将一个进程的寄存器状态保存到PCB中，然后将下一个进程先前保存的状态写入寄存器，从而切换到该进程执行。**

fork()刚完成时，两个进程的内存、寄存器、程序计数器等状态都完全一致，但他们是完全独立的两个进程，拥有不同的PID和虚拟内存空间，在fork完成后会各自独立运行，互不干扰。

fork()是一个“调用一次，返回两次”的系统调用，父进程中返回值是子进程的PID，子进程返回值是0。

**内核态的线程控制块（TCB）**存储线程的运行状态、内存映射、标识符等信息

**用户态的线程控制块**则主要由线程库决定，如Linux平台使用的pthread线程库的应用，pthread结构体就是用户态线程TCB，可认为是内核态的扩展，用来存储更多与用户态相关的信息，其中一项很重要的功能是线程本地存储。

**线程本地存储**（TLS）：实现“一个名字，多份拷贝”的全局变量，不同线程在使用该变量时，从代码层次看访问的同一个变量，但实际访问的是该变量的不同拷贝，从而实现线程内部的全局变量。

运行过程中，线程库回味每个线程创建结构完全相同的TLS，保存在内存的不同的地址上，在每个线程的TLS中，每个相同名字的变量都在相同的位置即相对于TLS的起始位置的偏移量都相等。

x86_64使用FS段寄存器实现TLS中变量寻址：当一个线程被调度时，pthread线程库会找到该线程TLS的起始地址，并存段寄存器FS中。不同线程的FS寄存器保存的TLS起始地址不同，从而实现不同地址的访问。
在AArch64中，TLS的起始地址将被存放在寄存器TPIDR_EL0中。



#### （36）写时拷贝（Copy On Write）

早期的fork实现会将父进程的物理内存完全拷贝一份，并映射到子进程内存空间中。

后期的fork会与父进程共享同一份物理地址空间，代码段、数据段、堆栈等都共享，直到相应的段发生改变时，再为子进程相应的段分配物理空间，如果不是因为exec造成的改变，内核会给子进程的数据段、堆栈分配相应的物理空间（此时父子进程各有独立的空间，互不干扰）但代码段继续共享同一段物理空间，如果是因为exec造成的改变，代码段也会被分配到独立的物理空间。

首先，一部分虚拟内存（共享代码库、代码段）是只读的，拷贝是一种浪费

其次，进程有时会调用fork后立即调用exec以载入新的可执行文件，重置地址空间，之前的内存拷贝就失去了意义

由此引入写时拷贝技术对fork的实现进行优化：对本来就只读的虚拟页（如代码段）来说，父进程和子进程**共享**这些页，**减少拷贝开销**；而对于容易发生变化的虚拟页（如堆、栈对应的页），如果出现写操作，就会触发写时拷贝，由操作系统负责处理。



 #### （37）多线程进程的地址空间布局

首先是分离的内核栈和用户栈：每个线程的执行相对独立，进程为每个线程都准备了不同的栈，内核中每个线程也有对应的内核栈，在线程切换到内核中执行时，栈指针就会切换到对应的内核栈

其次是共享的其他区域：进程**除栈以外的其他区域**由该进程的所有线程共享，包括堆、数据段、代码段等。

同一进程下多个线程的动态分配内存是在同一个堆上完成的（**C语言中malloc实现需要使用同步原语**）。



#### （38）POSIX线程库

一般称为pthreads，遵照POSIX标准提出的一套线程接口，不同操作系统根据自己的需求提供了实现。

主要接口：

- pthread_create，在当前进程中创建一个新进程，并运行第三个参数start_routine指定的函数，同时，pthread_create的使用者可使用第二个参数attr为线程指定一些属性，并使用第四个参数为函数start_routine设定参数。pthread_create执行成功后，第一个参数thread会被填入指向新创建的线程的引用。

  ```c++
  int pthread_create(pthread_t *thread, 
                     const pthread_attr_t *attr,
                     void *(*start_routine) (void *),
                     void *arg);
  // 通过clone实现，实际创建处一个从属于原进程、与原进程共享大量数据结构、拥有私有栈的实例，对应着一个进程。
  //const int clone_flags = (CLONE_VM | CLONE_FS
  //                         | CLONE_FILES | CLONE_SYSVSEM
  //                         | CLONE_SIGHAND | CLONE_THREAD
  //                         | CLONE_SETTLS | ... );
  //ARCH_CLONE (&start_thread,STACK_VARIABLE_ARGS,clone_flags,...);
  ```

- pthread_exit，用于线程终止并退出，其调用并不是必要的，当一个线程的主函数执行结束时，pthread_exit将会被隐式调用，但其显式调用提供了表示线程的返回值的参数。

  ```c++
  void pthread_exit(void *retval);
  ```

- pthread_yield，主动暂停，让出CPU。返回值为该操作执行的结果，直接调用sched_yield系统调用，放弃CPU资源，但仍旧是预备状态，可能马上就会被调度。

  ```c++
  int pthread_yield(void)
  ```

- pthread_join，多线程协作时可能出现线程之间的执行存在相互依赖的情况，线程哭会提供合并（join）操作，允许一个线程等待另一个线程的执行，并获取其执行结果。在pthread_exit的返回值可以用在多个线程协作的场景中。

  ```c++
  // thread为需要等待的线程
  // retval是一块内存，用于接收被等待线程的返回值，此返回值就是调用pthread_exit时设定的返回值，将其从被等待线程的内存拷贝到当前线程指定的地址
  int pthread_join(pthread_t thread, void **retval);
  ```

- sleep，进入阻塞状态，让出计算资源给其他线程。即挂起机制，sleep用户等待固定时间。但pthreads没有提供等待固定时间的接口，线程可以使用POSIX中的sleep接口，内核将对应线程置为阻塞，当时间过去后，内核将其唤醒，置为预备状态，允许继续执行。

- pthread_cond_wait，挂机机制，等待具体事件，在pthreads中对应pthread_cond_wait

  ```c++
  // 线程将等待在cond上，挂起线程
  int pthread_cond_wait(pthread_cond_t *restrict cond,
                        pthread_mutex_t *restrict mutex);
  ```

  类似的等待接口有pthread_cond_timedwait，相当于等待具体事件和等待固定时间的结合，还接收一个额外的时间参数abstime，如果等待时间超过abstime或cond被其他线程使用pthread_cond_signal操作，内核将其唤醒。

  

---------



## 数据库

#### （1）三大范式

第一范式：表中所有字段值都是不可分解的原子值

第二范式：所有非主属性都完全依赖于主码

第三范式：所有非主属性对任何候选关键字都不存在传递依赖（即跟主键有直接关系）

#### (2) HAVING 和 WHERE 的差别

WHERE 在数据分组前进行过滤，排除的行不包括在分组中

HAVING 在数据分组后进行过滤

#### (3) ORDER BY 和 GROUP BY的区别

ORDER BY 排序产生的输出，任何列都可以使用

GROUP BY 用于分组行，但输出可能不是分组的顺序，只可能使用选择列或表达式列而且必须使用每个选择列表达式

#### (4) Mysql 中子句的书写顺序和执行顺序

书写顺序

```mysql
SELECT xxx 
FROM left_table
JOIN right_table 
ON join_cond
WHERE
GROUP BY
HAVING
ORDER BY
LIMIT
OFFSET
```

执行顺序

```mysql
FROM
ON
JOIN
WHERE
GROUP BY
HAVING
SELECT
DISTINCT
ORDER BY
LIMIT
```



#### （5）脏读、不可重复读、幻读、丢失修改

当多个事务并发执行时，可能会出现以下问题：

- 脏读：事务A更新了数据，但还没有提交，这时事务B读取到事务A更新后的数据，然后事务A回滚了，事务B读取到的数据就成为脏数据了。 
- 不可重复读：事务A对数据进行多次读取，事务B在事务A多次读取的过程中执行了更新操作并提交了，导致事务A多次读取到的数据并不一致。 
- 幻读：事务A在读取数据后，事务B向事务A读取的数据中插入了几条数据，事务A再次读取数据时发现多了几条数据，和之前读取的数据不一致。 
- 丢失修改：事务A和事务B都对同一个数据进行修改，事务A先修改，事务B随后修改，事务B的修改覆盖了事务A的修改。 

不可重复度和幻读看起来比较像，它们主要的区别是：在不可重复读中，发现数据不一致主要是数据被更新了。在幻读中，发现数据不一致主要是数据增多或者减少了。

数据库的隔离级别分别可以解决数据库的脏读、不可重复读、幻读等问题。

| 隔离级别 |  脏读  | 不可重复读 |  幻读  |
| :------: | :----: | :--------: | :----: |
| 未提交读 |  允许  |    允许    |  允许  |
|  提交读  | 不允许 |    允许    |  允许  |
| 可重复读 | 不允许 |   不允许   |  允许  |
|  串行化  | 不允许 |   不允许   | 不允许 |

**MySQL的默认隔离级别是可重复读。**

#### （6） 聚集索引 vs 非聚集索引

聚簇索引和非聚簇索引最主要的区别是**数据和索引是否分开存储**。

- 聚簇索引：将数据和索引放到一起存储，索引结构的叶子节点保留了数据行。 
- 非聚簇索引：将数据和索引分开存储，索引叶子节点存储的是指向数据行的地址。 

在InnoDB存储引擎中，默认的索引为B+树索引，利用主键创建的索引为主索引，也是聚簇索引，在主索引之上创建的索引为辅助索引，也是非聚簇索引。为什么说辅助索引是在主索引之上创建的呢？因为辅助索引中的叶子节点存储的是主键。

在MyISAM存储引擎中，默认的索引也是B+树索引，但主索引和辅助索引都是非聚簇索引，也就是说索引结构的叶子节点存储的都是一个指向数据行的地址。并且使用辅助索引检索无需访问主键的索引。

#### （7） 慢查询优化

什么是慢查询：执行时间超过某个临界值的SQL语句

相关参数：slow_query_log是否开启、slow_query_log_file慢查询日志存储路径、slow_query_time阈值、log_output存储方式(FILE/TABLE)等

如何优化：

- 分析语句的执行计划，索引是否命中【是否扫描了太多行、是否返回了太多列、添加缓存、了解查询执行过程】
- 优化数据库结构
- 优化LIMIT分页
  - 越往后分页，偏移量越大，速度越慢，此时可以通过子查询（在索引上完成）的方式提高效率
  - 采用JOIN分页？

#### (8) CAS操作

三个基本操作数：内存地址、旧预期值、要修改的新值

重新尝试的操作：重新获取内存地址，并重新计算想要修改的值，这个操作被称为自旋

缺陷：自旋带来的CPU开销、只能保证一个共享变量的原子操作而不能保证代码块的原子性、存在“ABA”行为【加上版本号可以解决】

#### （9） STEAL 和 FORCE策略

![img](http://ww4.sinaimg.cn/large/7cc829d3jw1f3dre5heh5j20hm0acjt7.jpg)

第5步可能在提交之后完成，因为一旦发生崩溃，还有可能利用REDO日志恢复事务，即为NO-FORCE策略

可以采用FORCE策略（如第5步在提交之前必须完成）来降低恢复时的负载

数据是一步步的写入（STEAL策略）还是缓冲管理器需要等待提交命令一次性全部写入（NO-STEAL策略），取决于想要什么：快速写入但从UNDO日志中恢复缓慢还是快速恢复

STEAL/NO-FORCE -- 需要UNDO和REDO，性能高，但日志和恢复过程复杂

STEAL/FORCE -- 只需要UNDO

NO-STEAL/NO-FORCE：只需要REDO

NO_STEAL/FORCE：什么都不需要，性能最差而且需要巨大内存



## MySQL

#### （1）基本子句

```mysql
USE databse_name;

SELECT *
FROM customers
WHERE birth_date > '1990-01-01'  -- AND / OR / NOT / BETWEEN ... AND ... / IN / LIKE / REGEXP / IS NULL / IS NOT NULL 
ORDER BY fitst_name
LIMIT offset_value,3;

-- 内连接（返回交集）
SELECT *
FROM orders
JOIN customers ON orders.customer_id = customers.curstomer_id;

-- 跨数据库连接
SELECT *
FROM order_items oi
JOIN sql_inventory.products p ON io.product_id=p.product_id;

-- 自连接
SELECT *
FROM employees e
JOIN employee m ON e.reports_to=m.employee_id;

-- 多表连接
SELECT *
FROM orders o
JOIN customers c ON c.customer_id=c.customer_id
JOIN order_statuses os ON o.status=os.order_status_id 

-- 复合连接条件
SELECT *
FROM order_items oi
JOIN order_item_notes oin ON oi.order_id = oin.order_id AND oi.product_id=oin.product_id

-- 隐式连接
SELECT * 
FROM orders o, customers c  -- 没有where就变成了笛卡尔积
WHERE o.customer_id=c.customer_id;

-- 外连接
SELECT *
FROM customers c
LEFT JOIN orders o ON c.customers_id=o.customer_id -- LEFT JOIN会返回customers的所有记录，无论是否为空
ORDER BY c.customer_id

-- 多表外连接
SELECT *
FROM customers c
LEFT JOIN orders o ON c.customer_id=o.customer_id
LEFT JOIN shippers sh ON o.shipper_id=sh.shipper_id
ORDER BY c.customer_id

-- 自外连接
SELECT *
FROM employees e
JOIN employees m ON e.reports_to=m.empoyee_id

-- 如果两个表中列名称一致，可使用USING替代ON

-- 自然连接，不建议使用
SELECT *
FROM orders o
NATURAL JOIN customers c

-- 交叉连接
	-- 显式
SELECT *
FROM customers c
CROSS JOIN products p -- 两个表的每条记录都连接即笛卡尔积
	-- 隐式
SELECT *
FROM customers c, orders o

-- UNION
SELECT first_name
FROM customers
UNION
SELECT name
FROM shippers

-- INSERT
INSERT INTO customers
VALUES (DEFAULT,'John','Smith','1999-01-01',NULL,'address','city','CA',DEFAULT) -- DEFAULT 用于自增的列或有默认值的列，这种方式必须插入所有列

INSERT INTO customers (first_name,last_name,birth_date,address,city,state)
VALUES ('John','Smith','1999-01-01','address','city','CA')

INSERT INTO shippers (name)
VALUES ('shipper1'),('shipper2'),('shipper3')
```



#### （2）in和exist的区别

二者均用于子查询，但exist适合于外小内大的场景，in适合于外大内小的场景。

- exist先外再内，in先内再外
- in在内外查询均会使用索引，而exist仅在内查询使用索引
- 如果子查询的结果集较大，外表较小时exist效率更高，而如果子查询结果较小，外表较大时in效率更高
- not exists 效率比 not in高，因为not in对内外表都进行了全表扫描，而not exists子查询可以用索引



#### （3）临时表

临时表分为内存临时表（使用MEMORY存储引擎）和磁盘临时表（使用MyISAM存储引擎）

使用场景：

- FROM子查询
- DISTINCT  + ORDER BY
- ORDER BY 与 GROUP BY的子句不一样时
- UNION



#### （4）分表分库策略

水平拆分：同一个表拆到不同的数据库（水平分库）或拆成多张小表（水平分表）

垂直拆分：不同的表拆到不同的数据库（垂直分库）或拆分字段到多个表（垂直分表）

分表分库后ID的处理方案即全局ID：

- UUID，本地生成，全局唯一不重复，但占用空间且不适合作为索引
- 自增ID，需要有一个专门生成主键的库，每次都要先插入一次然后获取一个ID再去写数据，实现简单但高并发性能受限



#### （5）not null

- null和空值不一样
- NULL影响函数统计，如COUNT不会统计在内
- B树不存储NULL，所以索引不到NULL（上面COUNT统计不到的原因）
- NOT IN 子句查询在有NULL值的情况下返回结果全是空值



#### （6）优化

- UNION 不如 UNION ALL效率高
- 尽量不要在WHERE子句中使用不等于判断（因为会全表扫描而不是使用索引）
- WHERE 和 ORDER BY 涉及的列考虑建立索引



#### （7）执行顺序

```
SELECT DISTINCT select_list
FROM left_table
LEFT JOIN right_table ON join_condition
WHERE where_condition
GROUP BY group_by_list
HAVING having_condition
ORDER BY order_by_condition

=>
FROM -> ON -> JOIN -> WHERE -> GROUP BY -> HAVING -> SELECT -> DISTINCT -> ORDER BY
```



#### （8）主从复制

主从复制，是用来建立一个和主数据库完全一样的数据库环境，称为从数据库，主数据库一般是准实时的业务数据库。一般在数据量较大的情况下会考虑，当然我们做的单机程序可能用不到这些内容，但是现在是个大数据时代，各种技术都会和分布式相联系，主要是为了进行负载均衡，**数据库的主从复制其实就是为了解决数据过大，单机进行增删改查压力会比较大**，所以把数据的增删改和查分开即**读写分离**。同时也起到备份的作用，提高了单个机器的I/O性能。

主要方式有一主一丛，主主复制（高容灾方案），一主多从（适合增删改少，查询多的业务），多主一从（适合增删改多，查询少的业务），联级复制。

原理：涉及到三个线程binlog线程、I/O线程、SQL线程

binlog输出线程：bin-log中记录所有的sql语句，主服务器创建一个线程将bin log的数据写入从库中

从库I/O线程：读取bin log，连接到主库并请求发送bin log的更新记录到从库，读取bin log线程发送的更新，并拷贝这些更新到本地文件，其中包括relay log

从库SQL线程：读取从库I/O县城写到relay log的更新时间，并重放

作用：负载均衡、备份机制、提升可用性



#### （9）读写分离

读写分离主要依赖于主从复制，主从复制为读写分离服务

**一般而言，主服务器负责写，从服务器负责读。**

- 缓解锁的竞争
- 主从服务器可以使用不同的存储引擎，提升查询性能
- 增加冗余，提高可用性



#### （10）drop、truncate、delete区别：

drop，删除数据和表结构（全部释放）

truncate，清空表数据但保留表结构，不记录日志（只记录释放）不能恢复，没有激活触发器，执行速度快（表和索引会恢复到原始大小、索引还在）

delete，删除行，记录在日志，支持事务和触发器；



####  （11）误操作快速回滚

TODO



#### （12）锁

- 全局锁：主要用于全库逻辑备份，缺点是如果数据库引擎不支持可重复读的隔离级别，则会造成业务停滞。

  ```mysql
  -- 使用
  flush tables with read lock
  -- 释放
  unlock tables 
  ```

- 表级锁

  - 表锁

    ```mysql
    -- 表级别的共享锁，读锁
    lock tables table_name read;
    -- 表级别的独占锁，写锁
    lock tables table_name write;
    -- 释放
    unlock tables
    ```

  - 元数据锁（MDL）

    作用：保证用户对表执行CRUD操作时，防止其他线程对表结构做变更

    ```mysql
    -- 无须显式使用，当对数据库表进行操作时，自动给相应表加上MDL
    -- 对一张表进行CRUD操作时，加MDL读锁
    -- 对一张表进行结构变更操作时，加MDL写锁
    -- 事务执行期间，MDL一直持有。事务提交后才释放
    ```

  - 意向锁

    目的是快速判断表里是否有记录被加锁

    在给表中某些记录加共享锁之前，需要在表级别加上意向共享锁

    在给表中某些记录加独占锁之前，需要在表级别加上意向独占锁

    **普通select语句不会加行级锁，利用MVCC实现一致性读（无锁操作）**

    ```mysql
    -- 先在表上加意向共享锁，然后对读取记录加独占锁
    select ... lock in share mode;
    -- 先在表上加意向独占锁，然后对读取记录加独占锁
    select ... for update;
    ```

    意向共享锁和意向独占锁是表级别锁，不会与行级的共享锁和独占锁冲突，而意向锁之间也不会发生冲突，**但会和共享表锁、独占表锁发生冲突**

  - AUTO-INC锁

    特殊的表锁机制，不是在一个事务提交后才释放，而是在执行完插入语句后就立即释放，插入数据时，会加一个表级别的AUTO-INC锁，然后为AUTO_INCREMENT修饰的字段赋值递增的值，等插入语句执行完成后，才把AUTO-INC锁释放。

    为了解决插入大量数据时带来的性能问题，引入一个**轻量级的锁**来实现自增，在插入数据时，会为被AUTO_INCREMENT修饰的字段加上轻量级锁，然后赋值，然后释放轻量级锁，而不需要等待整个插入语句执行完才释放。

    系统变量`innodb_autoinc_lock_mode`用于控制选择AUTO-INC锁还是轻量级锁，默认情况下两种锁混用（根据插入的记录数目设置阈值）

    为什么不一直直接使用轻量级锁？因为并发插入时，每次插入时的自增长的值可能不是连续的，这导致在有些主从复制场景中不安全。

- 行级锁

  - Record Lock

    锁住一条记录

  - Gap Lock

    锁定一个范围（前开后开区间），但不包含记录本身

  - Next-Key Lock

    锁的是索引，而不是数据本身，锁住一个范围（前开后闭区间），同时锁住记录本身。

    在某些场景下会退化为记录锁或间隙锁。

    - 唯一索引等值查询 --  查询记录存在时，退化为Record Lock，查询记录不存在时，退化为Gap Lock
    - 唯一索引范围查询 -- 范围查询时如果记录不存在会退化到末尾的Gap Lock
    - 非唯一索引等值查询 --查询记录存在时，会加next-key lock和gap lock（两把锁，间隙锁遍历到向下第一个不符合条件的值停止），查询记录不存在时，next-key lock退化为gap lock
    - 非唯一索引范围查询 -- 普通索引范围查询，next-key lock不会退化为Gap Lock和Record Lock

#### （13） MVCC

读提交和可重复读都是通过Read View实现的，区别在于创建Read View的时机不同，读提交是在每个读取数据前都生成一个Read View，而可重复读是启动事务时生成一个Read View，然后整个事务期间都用这个Read View。

Read View的四个字段：

- m_ids: 创建Read View时当前数据库中活跃且未提交的事务的**事务id列表**
- min_trx_id:创建Read View时当前数据库中活跃且未提交的事务中最小事务id
- max_trx_id:创建Read View时当前数据库中应该给下一个事务的id值
- creator_trx_id:创建该Read View的事务id

聚集索引记录中两个隐藏列：

- trx_id: 当一个事务对某条聚集索引记录进行修改时，就会把该事务的事务id记录在trx_id隐藏列中
- roll_pointer: 每次对某条聚集索引记录进行改动时，都会把旧版本的记录写入到undo日志中，然后用这个隐藏列（指针）指向每个旧版本记录，从而可以找到修改前的记录

可重复读隔离级别下，读取数据时，在找到数据后，先会比较记录的trx_id和事务的Read View中的creatoor_trx_id

- 如果记录的trx_id比creator_trx_id小，且不在m_ids列表里，则意味着数据在事务创建之前提交，所以记录对事务可见；
- 如果记录的trx_id比creator_trx_id大，且在m_ids列表里，则意味着事务读到的是和自己一起启动的另一个事务修改的，不应该读取这条记录，而是沿着undo log链条往下找旧版本的记录，直到找到trx_id等于或小于该事务id的第一条记录

 => 这种方式就叫做多版本并发控制（MVCC）



读提交隔离级别下，每个select都会生成一个新的Read View，如果事务期间多次读取同一条记录，前后两次可能不一致即（不可重复读）。通过判断记录的trx_id和事务的Read View中creator_trx_id

- 如果前者较大，且在m_ids列表中，说明记录被另一个事务修改过且尚未提交【因为如果提交了，这条记录的trx_id就不会在m_ids列表中】，此时沿着undo log往下查找；
- 如果前者较小，且不在m_ids列表中，说明记录trx_id的事务已经提交过。

在可重复读隔离级别下，普通查询是**快照读**，其他都是**当前读**如update、insert、delete等，在执行前都会查询最新版本的数据，然后做进一步操作。

**Innodb引擎为了解决【可重复读隔离级别】使用【当前读】造成的幻读问题，引出next-key锁。**【TODO】



#### （14） 索引为什么能提高查询性能

首先，数据存储在磁盘中，磁盘上数据存储很慢，**提高性能主要通过减少I/O次数以及单次I/O有效数据量**

其次，索引通过多阶使树变得更加矮胖，从而减少I/O次数

再次，通过B+树，将业务数据和索引数据分离，提高单次I/O有效数据量，从而减少I/O次数

最后，索引通过树数据的有序和二分查找，快速缩小数据范围 



#### （15）数据库分页查询

```mysql
SELECT *
FROM table_name
WHERE ...
LIMIT [offset,]num //返回第[offset]-[offset+num]行的数据
```



#### （16）ACID底层原理（MySQL）

原子性是通过undo log实现的，一个事务如果发生错误异常或显式rollback时，需要将数据回滚到之前的状态，使用undo log来实现。而undo log的生成是在每条数据变更（insert/update/delete）操作都伴随着一条undo log生成，并且回滚日志必须先于数据持久化到磁盘，然后对于每条回滚操作，都做逆向操作（delete->insert，insert->delete，update->update等）

一致性是通过原子性、持久性、隔离性实现的

隔离性是通过读写锁+MVVC实现的，四种隔离级别的实现均不一样。

持久性是通过redo log实现的，读数据时首先从缓冲池中读取，如果没有则从磁盘放入缓冲池，写数据时先写入缓冲池，定期同步缓冲池到磁盘。如果数据库系统宕机，缓冲池中数据未写入磁盘，此时redo log就可以用上了。这里redo log的存储是顺序存储的，而缓冲同步是随机行为，并且缓存同步是以数据页为单位的，每次传输的数据大小大于redo log。



#### （17）索引原理

首先表中设有主键是有原因的：将表变成一个索引即所谓的“聚集索引”，将无序数据变成顺序数据，但一个表只能有一个主键。

通过索引，从根节点到叶节点到过程就是不断缩小查找范围的过程，缩小速度是对数级别而不是一个一个比对的线性级别。

那么什么是“非聚集索引”即平常提到和使用的索引？非聚集索引同样是采用平衡树作为索引的数据结构，只是各个节点的值是索引的字段，每个索引（非聚集索引）相互之间不存在关联，相互独立。而每次给字段建一个新索引，字段中的数据就会被复制一份，用于生成索引，也就会增加表的体积，自然要占用磁盘存储空间。和聚集索引的区别在于，通过聚集索引可以查到需要查找的数据，而通过非聚集索引可以查到记录的主键值，再使用主键的值通过聚集索引查找需要的数据。

那么“覆盖索引”（“复合索引/多字段索引”）又是怎么回事呢？当使用覆盖索引查询数据时，除了有主键值外，复合索引中字段值也在叶节点中，因此可能并不需要查找数据行的真实所在，直接从叶节点中的相应值返回即可，可以省略使用覆盖索引查找的后续步骤，提升了查询性能。

“最左匹配“是指优先比较左侧的数据项，直到匹配到范围查询（<、>、between、like等）缩小范围，进而提高查询速度。

“唯一索引”可以保证数据记录的唯一性

“普通索引”的唯一任务是加快对数据的访问速度

#### （18）日志系统

日志可以分为逻辑日志和物理日志。前者存储了逻辑SQL修改语句，后者存储了数据被修改的值。

bin log作为MySQL的逻辑日志，由MySQL Server来记录，用于记录用户对数据库操作的SQL语句（不包括查询语句）信息，以二进制形式保存在磁盘中，通过追加方式写入。默认格式时STATEMENT，每一条会修改数据的SQL语句都会记录到bin log中，另一种格式是ROW，是基于行的复制，仅保存哪一条记录被修改而不记录每一条SQL语句的上下文信息。而MIXED是混合复制，一般的复制采用STATEMENT模式，对于STATEMENT模式无法复制的操作则使用ROW模式保存，MySQL根据执行的SQL语句选择保存模式。

redo log作为MySQL的物理日志，记录存储引擎InnoDB的事务日志。每执行一条SQL更新语句，不是每次数据更改都立刻写到磁盘，而是先将记录写到redo log中，并更新内存，一段时间后再将多个操作落盘即WAL技术（Write-Ahead Logging）。在MySQL中redo log是固定的。

二者均存在的理由：bin log只用于存档，不具备crash safe能力，而redo log是InnoDB特有的，且落盘后会被覆盖。二者均存在才能保证数据库发生宕机重启时，数据不会丢失。



---



### 额外的一些概念

#### 什么是启发式算法

它根据一条规则（或启发），保存上一步找到的方法，『附加』到当前步骤来进一步搜寻解决方法。有些算法根据特定规则，一步步的应用规则但不总是保留上一步找到的最佳方法。它们统称启发式算法。





----

### 设计模式

适配器模式：有时也称为包装，将一个类的接口转换成用户所期待的，做法是将类本身的接口包裹在在一个已存在的类中

代理模式：为其余对象提供一种代理以控制这个对象的访问，适用于一个对象不适合或不能直接引用另一个对象，而代理对象能在二者之间起到中介作用

#### 适配器模式和代理模式的区别

适配器模式是由于新旧接口不一致导致客户端无法匹配的问题，为了使用之前实现旧接口的服务，将新接口转化为旧接口

代理模式提供的接口与原始接口一致，但为了不将实现直接暴露给客户端，而是通过代理层获取访问权限和一些处理。

----



## 网络编程模型

网络编程模型处理的主要流程：
Initiate -> receive ->. demultiplex -> dispatch -> process events

#### Reactor模型

典型的事件驱动的编程模型，逆置了程序处理的流程，基本思想是`Hollywood Principle -- Don't call us, we'll call you`

事件处理机制：主程序以及对应事件处理方法在Reactor上注册，如果相应事件发生，Reator主动调用事件注册的接口即回调函数。

要求主线程只负责监听文件描述符上是否有事件发生，如果有则立即将该事件通知工作线程。

工作线程完成读写数据、接受新连接、处理客户请求等工作

模型组件

- Reator，事件管理的接口，内部使用event demultiplexer注册，注销事件，并运行事件循环，当有事件进入就绪状态时，调用注册事件回调函数处理事件。

- 句柄Handle，一般指Socket Handle，网络连接的抽象
- 同步事件复用器Synchronous Event Demultiplexer，阻塞等待一系列的Handle中的事件到来，如果阻塞等待返回即表示返回的Handle中可以不阻塞的执行返回的事件类型。一般用select/poll实现。首先将handler以及对应的事件注册到事件复用器上，当事件到达时，事件复用器发出通知，Reator调用事件处理程序进行处理。
- Initiation Dispatcher，用于管理Evenet Handler注册、移除等，还作为调用select方法的入口，当阻塞等待返回时，根据事件发生的Handle将其分发给对应的Event Handler处理即回调Event Handler中的handler_event()方法
- Event Handler，定义事件处理方法，提供一组接口，当Reactor相应事件发生时调用，执行事件处理，通常会绑定一个有效的handler。handle_event()，供Initiation Dispatch回调使用
- Concrete Event Handler，实现特定事件处理逻辑

单Reactor单线程、单Reactor多线程、多Reactor多线程（一个Reactor处理新连接的建立，将建立的socketChannel指定注册给subReactor；subReactor维护自己的selector，基于mainReator注册的socketChannel多路分离I/O读写事件，读写网络数据，对于业务处理的功能交给worker线程池完成）

#### Proactor模式

整体结构和Reactor处理方式相似，不同的是Proactor采用的异步非阻塞I/O的方式，对数据的读写由异步处理而无须用户线程处理，服务程序可以专注于业务事件的处理而非I/O阻塞。

#### Asynchronous Completion Token

应对应用程序异步调用服务操作，并处理相应的服务完成事件。一种状态的保持和传递。

解决异步发起第三方请求的数据达到后，采用一个token记录异步发送前的信息，发送给接收方，接收方回复时带上token，恢复业务调用场景。

#### Acceptor-Connector

Reactor的变种，将网络中对等服务的连接和初始化分开处理，使系统中的连接建立及服务一旦服务初始化后就分开解除耦合。

连接器主动建立远程接受器的连接，并初始化服务处理器来处理连接上交换的数据

接受器被动等待远程连接器的连接请求，在请求到达时建立连接，并初始化服务处理器来处理连接上交换的数据

其好处是：

- 用于连接建立和服务初始化的策略变动频度远小于应用服务实现和通信协议
- 容易新增新类型的服务、新的服务实现和新的通信协议，又不影响现有的连接建立和服务初始化软件
- 连接角色和通信角色的解耦，连接角色只负责发起或接受连接，通信角色只负责数据交互
- 编程人员与低级网络编程API（如socket或TLI）类型安全性的缺乏屏蔽开
