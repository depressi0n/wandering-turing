[TOC]



## 网络

#### （1）什么是HTTP？

HTTP，超文本传输协议的缩写，互联网广泛使用的一种网络协议。默认使用80端口，由客户端发起请求，建立一个与服务器指定端口的TCP连接（可以引出TCP和UDP有什么不同，使用TCP的原因是打开一个网页会传送很多数据，TCP协议提供了传输控制，按序交付，错误纠正）

#### （2）HTTP 请求方式

GET、POST、HEAD、PUT、DELETE、TRACE、CONNECT、OPTIONS

其中GET和POST的区别：
GET一般用于向服务器获取数据，没有请求体，仅支持ASCII码，安全，幂等，明文，可缓存的
POST一般用于向服务器发送数据，有请求体，支持标准字符集，不安全的，非幂等，不可缓存


#### （3）HTTP/1.0 vs HTTP/1.1

HTTP/1.1 默认采用持久连接，在一个TCP连接上可以传送多个HTTP请求和响应，减少建立和关闭连接到消耗和延迟。

HTTP/1.1 允许客户端流水线操作，不用等待上一次请求到结果返回就可以发送下一次请求，以减少整个过程的时间消耗

HTTP/1.1 中Header中可以有Connection，当其值为close时，正在使用的TCP连接在请求处理完毕后就会被断掉，当其值均为Keep-alive时保持连接

HTTP/1.1 增加了请求头和响应头来改进和扩充HTTP/1.0的功能，如Host（支持一台Web服务器在同一个IP地址和端口上使用不同的主机名来创建多个虚拟Web站点），提供缓存控制策略（如Entity tag，If-Unmodified-Since，If-Match，If-None-Match等），支持断点续传（Range，状态码对应206），增加错误状态响应码，引入Cookie保存状态信息

#### （4） HTTP/2.0

多路复用：允许通过单一的HTTP/2连接发起多重的请求-响应消息，主要解决HTTP/1.1的串形文件传输【借助二进制分帧+流】和连接数限制问题【借助流】

二进制分帧：在HTTP/2和传输层（TCP or UDP）之间增加二进制分帧，改进传输性能

首部压缩：DEFLATE算法（SPDY算法，强制使用HTTPS），HPACK算法，每个请求都要发送消息头，通过维护一个词典差量更新

服务端推送：在客户端请求发送之前发送数据，可以缓存数据

#### （5）HTTP vs HTTPS

HTTPS = HTTP + SSL/TLS（Secure Sockets Layer，涉及非对称加密，对称加密，HASH算法，序列号机制防止重放）

HTTPS 要求在传输数据之前客户端和服务器之间进行证书认证、密钥协商，

TLS过程：

* 浏览器将一套加密规则（对称加密算法、非对称加密算法、MAC算法、Nonce）发送给服务器
* 服务器从中选择一组加密算法和MAC算法，并将自己的身份信息以证书的形式（网址、加密公钥、证书颁发机构、过期时间等）发送给浏览器
* 浏览器验证证书合法性，生成一串随机数作为**通信密钥**，并使用约定的HASH算法计算握手信息，使用通信密钥对握手信息加密，通信密钥用服务器的公钥加密，都发送给服务器
* 服务器使用私钥解密获取通信密钥，再使用通信密钥解密握手信息并验证HASH值，验证完成后使用通信密钥加密一段握手信息发送浏览器
* （协商完通信密钥之后重新进行一次加密规则的协商 === *有内鬼，终止交易*）
* 浏览器使用通信密钥解密握手消息并计算HASH，并验证。
* 之后所有的通信都使用通信密钥进行通信（如果报文太大，TLS会做分割形成多个记录，序列号也会在MAC算法中作为输入）

主要区别：证书、明文/密文传输、端口443/80

HTTPS通信过程（分为ECDHE握手、RSA握手，不同之处在于RSA握手是直接由客户端生成）：

- 客户端与服务器首先建立TCP连接（DNS获取IP，然后TCP三次握手）
- 客户端向服务端443端口发起请求（Client Hello），将一套算法（支持的协议版本、支持的加密算法、Hash算法、Nonce1）发送给服务器
- 服务器选择算法（确认版本、确认加密算法），并将自己的信息（网址、公钥、证书颁发机构、证书过期时间）【通过证书形式】和Nonce2发送给客户端
- 客户端验证证书合法性，验证通过后生成随机值（Nonce3，与Nonce1和Nonce2一起生成session key和MAC key），使用服务器的公钥加密将“握手信息（改用会话密钥通信和所有握手数据的摘要）” 都发送给服务器 
- 服务器解密，验证Hash值，并生成响应的密钥，发送“握手信息（改用会话密钥通信和所有握手数据的摘要）”给客户端
- 服务器和客户端之后的通信用协商的密钥进行请求/响应

[参考链接](http://www.360doc.com/content/20/1119/19/37113458_946750481.shtml)：建议查看，比这里更详细，有图更容易理解

#### （6）TCP和UDP有什么不同

TCP：面向连接的、可靠（三次握手+四次挥手、校验和、序列号、超时重传、流量控制、拥塞控制、确认应答机制）交付、流量控制、拥塞控制、全双工、面向字节流、仅支持一对一

UDP：无连接的、尽最大可能交付、面向报文、支持点对点+多播+广播

#### （7）TCP 3次握手和4次挥手

三次握手：（两次握手不行是因为只能客户端的起始序列号被确认，而服务端的序列号不会被确认，不一定可靠）

* 客户端发送数据包（SYN=1，seq=x），进入syn_sent状态，等待服务端确认
* 服务端回复数据包（SYN=1，ACK=x+1，seq=y），进入syn_rcvd状态（此时请求连接被放在半连接队列中，SYN攻击--发送大量半连接请求，占用半连接队列，耗费CPU和内存，可以通过缩短SYN Timeout事件或者限制给定IP的半连接数目来防范）
* 客户端确认数据包（ACK=y+1，seq=x+1），双方进入established状态

四次挥手：（双方确认对方的连接关闭，等待2MSL的原因是保证上一次连接的报文已经从网络中消失并且接收重发的第四次挥手）

* 客户端发送数据报（FIN=1，seq=z），进入fin_wait_1状态
* 服务端回复数据包（ACK=z+1），进入close_wait状态（半关闭状态，客户端已经没有要发送的数据但可以接受服务端的数据）
* 服务端发送数据包（FIN=1，seq=w），进入last_ack状态
* 客户端回复数据包（ACK=w+1）之前进入time_wait状态，回复后双方进入closed状态

#### （8）session 和 Cookie的区别

session： 由服务端产生，保存在服务端，session id存放在cookie中，一般用于用户验证

cookie： 由服务端产生，在客户端保存，一般用于标识客户端

#### （9）浏览器从输入网址到显示整个页面的经历

* 对域名进行格式化检查
* 根据域名查看本地缓存（检查是否过期，更新资源刷新缓存或读取缓存）
* 根据域名通过DNS解析得到IP地址，会经过ARP（广播询问，单播回复）获取网关的MAC地址，将数据包发送给网关，由网关交付给本地DNS服务器，查询IP地址，DNS查询会经历浏览器缓存-操作系统缓存-路由器缓存-ISP DNS 缓存-根域名服务器
* 与服务器指定端口建立TCP连接，经历三次握手（也需要经过上面的走网关交付路由器流程），建立连接后，发送HTTP请求，转成TCP报文交付给路由器，经过IP路由后交付给服务器，中间会经过MAC地址变化
* 服务器处理请求并回复
* 浏览器接收到响应资源后，对响应资源进行处理并解析响应内容
* 由浏览器内核对页面进行渲染（DOM树、CSS规则树、渲染树、JS执行）

#### （10） 网络协议模型

OSI七层协议：物理层（二进制比特流传输）、数据链路层（封装成帧，透明传输，差错检测CRC）、网络层（路由选择算法，IP首部，ARP、ICMP、IGMP，路由器，RIP/OSPF、BGP）、传输层（拥塞控制、流量控制、差错控制，提供进程间的逻辑通信）、会话层（建立--身份+权限、保持--维护、断开--释放）、表示层（数据格式编译）、应用层（HTTP协议、FTP协议等）

TCP/IP五层协议包括：物理层，数据链路层，网络层，运输层，应用层

#### （11）TCP粘包

TCP是面向字节流的，多个小尺寸数据可能被封装在一个TCP报文中，而接收方一次性读完
处理方法：固定发送消息长度，加入消息分隔符

#### （12）滑动窗口（流量控制） vs  拥塞控制 vs 差错控制

滑动窗口：接收方告知发送方 -- 接收窗口的大小，从而控制发送方的速度

拥塞控制：发送方维护拥塞窗口大小，慢开始（每接一次报文，指数增加）、拥塞避免（经过一个RTT，拥塞窗口加1）、快恢复（拥塞时将门限值设置为拥塞时发送窗口的一半，并将拥塞窗口设置为门限值）、快重传（三个ACK，不需要等待计时器超时）

差错控制：校验和、ACK、超时重传

#### （13）DNS协议

基于UDP的应用层协议，功能是根据域名解析出IP地址。

过程：

* 客户端发出查询请求，先在本地缓存中查找，未找到则发送给dns服务器
* 本地dns服务器在自己区域内查找，未找到则本地缓存中查找，仍未找到则将请求发送给根域名服务器
* 根域名服务器解析根域部分，回复包含下一级的dns服务器给本地dns服务器
* 本地dns服务器根据返回的信息接着访问下一级的dns服务器（递归），获取IP信息
* 本地dns服务器将查询结果返回给客户机
* 客户机收到添加缓存，完成解析过程

#### （14） ping命令使用哪些协议

ping命令使用的是ICMP协议（Internet控制报文协议，传输时封装在IP报文中）

#### （15）负载均衡

（1）什么是负载均衡

将工作负载分布到多个服务器来提高性能和可靠性的机制，涉及到的负载均衡算法有：轮询、最小连接、IP散列

（2）有哪些负载均衡？

七层（应用层）负载均衡：Nginx【用户态，相对比较重】

四层（传输层）负载均衡：LVS，修改报文头目标地址，如果需要也可修改源地址，接收到客户端的SYN请求时，通过负载均衡算法选择一个最佳服务器，并对报文中目标地址IP进行修改--最佳服务器IP，转发给该 服务器，TCP建立连接（客户端和服务器直接建立连接，LVS只起到一个类似路由器转发的功能）【LVS是Linux内核模块，工作在内核态】

三层（网络层）负载均衡：基于IP地址分流

二层负载均衡：基于MAC地址分流，粒度粗

DNS负载均衡：在解析域名时随机调度，类似于HTTP重定向转换策略



#### （16）TCP 延迟确认

TCP在处理交互数据流时，采用延迟确认以及Nagle算法来减少小分组数目

Nagle算法是为了尽可能发送大块数据，避免过多的小分组数目在网络中。基本定义：任意时刻，最多只能有一个未被确认的小段（小于MSS尺寸的数据块没有收到ACK）
基本规则：

- 如果包长度大于MSS，则允许发送
- 如果包含有FIN，则允许发送
- 设置TCP_NODELAY选项，则允许发送
- 未设置TCP_CORK选项时，若所有发出去的小数据包均被确认，则允许发送
- 上述条件不满足但发生了超时（200ms），则立即发送

Nagle事实上就是一个扩展的基于包的停止-等待协议。

延迟确认：TCP在接收到对端端报文后，不会立即发送ACK，而是等待一段时间发送ACK，以便将ACK和要发送的数据一块发送。
规则：

1. 当有响应数据发送时，ACK随数据一起发送
2. 没有响应数据，则ACK会有延迟，以等待是否有响应数据一起发送，但延迟一般在40ms-500ms之间（内核启动一个定时器，每个200ms就会检查一次，而不是设置某个时间值当定时器）
3. 如果在等待发送ACK期间，第二个数据又到了，则立即发送ACK

Cork算法：TCP不关注是否有收到ACK报文，只有当前缓存中积累的数量不足以组成一个full-size数据包时就不会将数据包发出，直到一个RTO超时才会把不满足full-size的数据包发送出去。
由TCP_CORK选项设置，优先级比TCP_NODELAY高。



#### （17） RPC vs HTTP 

RPC：远程过程调用，基于原生TCP通信，可自定义数据格式，速度快、效率高，需要双方使用相同的技术

HTTP：网络传输协议，基于TCP，规定了数据传输格式，但不关注语言的实现

二者都会基于socket，都可以实现远程调用，实现服务调用服务



#### （18） socket vs websocket vs HTTP长连接

HTTP长连接：本质上是请求/响应模式

WebSocket HTML5下的一种新协议，属于服务器推送技术的一种，握手使用HTTP实现（Upgrade/Connection/Sec-WebSocket-\*），本身属于应用层协议，复用了HTTP的握手通道，实现了浏览器和服务器的全双工通信，不同于HTTP长连接的地方是HTTP长连接是请求-响应模式，需要消息头【与socket其实没什么关系】

Socket 对TCP/IP协议的封装，只是接口而不是协议，一般情况下就是TCP连接



#### （19）RESTful

Representational State Transfer，表现层状态转换

RESTful 架构：

- 有一种资源，每种资源有唯一的URI来标识
- 对这种资源进行操作，实现状态转换，通常用HTTP方法来操作
- 客户端对服务器资源进行操作

RESTful API基于REST架构设计理念下利用HTTP协议描述和操作接口，主要涉及URL的设计、Request参数、Response数据

- URL的设计需要简单易懂，【协议】【域名】【路径】【方法】【参数】
- 常用的动作方法：

| 动作   | 说明                         |
| ------ | ---------------------------- |
| GET    | 读取 Read                    |
| POST   | 新建 Create                  |
| PUT    | 更新 Update                  |
| PATCH  | 更新 Update ，一般为部分更新 |
| DELETE | 删除 Delete                  |

- **其他操作：**

| 方法/资源 | http://example.com/users              | http://example.com/users/23 |
| --------- | ------------------------------------- | --------------------------- |
| GET       | 获取所有的用户信息                    | 获取用户id为23的信息        |
| POST      | 在所有用户信息中创建/追加一个新的用户 | 在id=23号用户新增信息       |
| PUT       | 更新该组用户信息                      | 更新id=23号的用户信息       |
| DELETE    | 删除所有的用户信息                    | 删除id=23号用户信息         |
| PATCH     | 更新所有用户部分信息                  | 更新id=23号用户信息         |

- URL的层级，可以定义为`GET /uesr/10/articales`，也可以定义为`GET /articles?user_id=10`

- 域名设计，可以采用独立域名`api.example.com`，也可以采用`example.com/api/users`。便于迁移

- 版本号，考虑到系统变化、迭代、兼容性，在API中引入版本号，可以在URL中加入版本号`GET api.example.com/v1/users`【便于操作】，也可以在请求头信息中加入`Accept: applicatio/example.com+json; version=3`【基于同一种资源的不同表现形式】

- 可选、复杂参数使用查询字符串

  - 过滤

    **比如某一个用户已经发表的文章**：
    `GET /users/10/posts?state=published`
    `GET /users/10/posts?published=true`

  - 分页

    **比如用户分页**：
    `GET /users?page=1&page_size=10`

    **在加条件，某一个用户已经发表的文章太多，需要分页**：
    `GET /users/10/posts?published=true&page=2&page_size=10`

  - 多字段排序

    **针对多个字段，不同的排序：**
    搜索用户，并按照注册时间升序、活跃度降序
    `GET /users?q=key&sort=create_time_asc,liveness_desc`

  - 显示某些字段

    `GET /users?fields=id,title,desc;`

  - github的api查看地址：**https://api.github.com/**

- 非资源特殊请求

  `GET /translate?from=de_DE&to=en_US&text=Hallo`
  `GET /calculate?para2=23&para2=432`

  在这种情况下，API响应不会返回任何资源。而是执行一个操作并将结果返回给客户端。因此，您应该在URL中使用动词而不是名词，来清楚的区分资源请求和非资源请求。

- 返回格式和状态码统一

- 最好做到Hypermedia即返回结果中提供链接，连向其他API方法，使用户不查阅文档也知道下一步应该做什么

- 设计技巧

  - `/`表示资源层级关系
  - `?`过滤资源
  - `,`或`;`表示资源同级层关系
  - `_`或`-`比啊时更友好的URL形式


------



## Linux

#### （1）awk

|      内部变量      |             含义             |
| :----------------: | :--------------------------: |
|         $0         |            当前行            |
| \$1,\$2,\$3...,\$n |      当前行的第n个字段       |
|         NF         |       当前行的字段数目       |
|       FNR/NR       |             行号             |
|         FS         |       分隔符，默认空格       |
|        OFS         |     输出分隔符，默认空格     |
|         RS         |     行分隔符，默认换行符     |
|        ORS         |   输出行分隔符，默认换行符   |
|      FILENAME      | 当前处理的文件名，默认换行符 |

支持正则表达式
 `/root/{ statements}` 匹配所有包含“root”的行，对应sed中`/root/p`
`$5~/root/{statements}` 匹配第5个字短包含“root”的行

支持地址定位 
`NR==1,NR==5 {statements}` 打印第2行到第5行，对应sed中`1,5p`

#### （2）sed

```shell
sed [-hnV][-e<script>][-f<script文件>][文本文件]
```

参数说明：

- -e\<script\>或--expression=\<script\> 以选项中指定的script来处理输入的文本文件。
- -f\<script文件\>或--file=\<script文件\> 以选项中指定的script文件来处理输入的文本文件。
- -h或--help 显示帮助。
- -n或--quiet或--silent 仅显示script处理后的结果。
- -V或--version 显示版本信息。

动作说明

- a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)

- c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！

- d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚；

- i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；

- p ：打印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～

- s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 将1-20行的old换成new

  

#### （3）grep

```shell
grep [-abcEFGhHilLnqrsvVwxy][-A<显示行数>][-B<显示列数>][-C<显示列数>][-d<进行动作>][-e<范本样式>][-f<范本文件>][--help][范本样式][文件或目录...]
# -o 只输出匹配的行
# -x 只输出没有匹配的韩
# -n 打印匹配的行号
# -i 忽略大小写
# -I 只打印文建明
```



#### （4） wc

```shell
wc [-clw][--help][--version][文件...]
```

**参数**：

- -c或--bytes或--chars 只显示Bytes数。
- -l或--lines 显示行数。
- -w或--words 只显示字数。
- --help 在线帮助。
- --version 显示版本信息。

默认情况下计算行数、字数、字节数



#### （5）find

```shell
find [-H | -L | -P] [-EXdsx] [-f path] path ... [expression]
```



#### （6）xargs

给命令传递参数的过滤器，可以将管道或标准输入数据转换为命令行参数，也可以从文件的输出中读取数据；可以将单行或多行文件输入转换为其他格式

-n 多行输出
-d 自定义分隔符
-I 指定一个替换字符串，每一个参数都会执行一次命令



#### （7）内存映射

将需要访问的文件映射到一个进程的虚拟地址内，访问虚拟地址相当于访问文件，从磁盘访问变成了内存访问。



#### （8）使用`kill -9`杀不掉一个进程怎么办？

发送SIGKILL信号给进程将其终止，两种情况下不适用：

（1）僵尸进程，已经释放了所有资源但没有被父进程释放，要等到父进程结束或重启才会被清除



```
$ ps -A -o stat,ppid,pid,cmd |grep -e '^[Zz]' # 寻找到僵尸进程
# -A 列出所有进程
# -o 自定义输出字段
# zZ 僵尸进程
kill -HUP [ppid]
```

（2）核心态进程，等待不可获得的资源，会忽略所有信号 => 只能重启







------------







## OS

#### （1）什么是OS

管理计算机软硬件资源的程序，提供给用户和硬件之间的接口，向上对用户程序提供接口，向下管理资源，负责处理器调度（公平、非阻塞、优先级）、内存管理（抽象足够大的虚拟内存内存空间，共享内存）、I/O（设备）管理（屏蔽不同设备之间的差异、提供并发访问）、文件系统（易用性）、健壮性管理、安全性管理，保证计算机资源公平竞争和使用，防止对计算机资源的非法侵占和使用，并保证自身正常运转。

#### （2）用户态和内核态

为了避免操作系统和关键数据被用户程序破坏，将处理器的执行状态分为内核态和用户态。

内核态是操作系统管理程序执行时所处的状态，能够执行包含特权指令在内的一切指令，能够访问系统内所有的存储空间。

用户态是用户程序执行时处理器所处的状态，不能执行特权指令，只能访问用户地址空间。

用户程序运行在用户态,操作系统内核运行在内核态。

切换：系统调用（软中断）、异常（内中断，由错误引起如文件损坏、缺页故障等）、外部中断（硬中断）

#### （3）虚拟内存

对主存的抽象，提供三个能力：

* 将主存看成一个存储在磁盘上的地址空间的高速缓存，主存中只保存活动区域，根据需要替换数据，高效利用主存
* 为每一个进程提供一致的地址空间，简化内存管理
* 保护进程的地址空间不被其他进程破坏

页面置换算法：

FIFO、LRU（最常用）、LFU

虚拟地址向物理地址的转换过程：

* 虚拟地址=虚拟页号+页偏移，首先查快表（存放在内存管理单元--MMU中）中页面映射关系，失败（可并行）则页表（虚拟页号->页框号）中找到页框号
* 真实地址=物理页地址+页偏移 

每个进程的控制信息中存储当前进程“页目录”的物理地址，通过这个地址找到“页目录”，其中存储物理内存页起始地址的“页表”，32位下这样的两级页表足够存储寻址空间为4GB大小的内存空间了。利用页表中存储的记录中存储的内存页起始地址（因为起始地址必然是对应一个4KB的页，所以低12位是全0，可以用这些位记录页相关信息如是否可读、可写、可执行、是否已经映射等信息 ）】

#### （4）进程通信 vs 线程通信

进程通信

​	匿名管道（pipe）：调用pipe函数创建，返回两个文件描述符，一个用于读，一个用于写，**只支持半双工通信（单向交替传输）**，只能在父子进程或兄弟进程中使用，随进程消亡而消亡，linux中用`|`表示，存在于内存的特殊文件，系统调用是`pipe`，返回两个描述符，一个读取端描述符`fd[0]`，一个写入端描述符`fd[1]`，使用`fork`创建子进程时会复制父进程的文件描述符，从而两个进程各有一组写入/读取描述符，从而实现跨进程通信，为了避免写入/读取混乱，创建子进程后，父进程关闭读取端，子进程关闭写入端。所以一般为了实现双向通信，需要创建两个管道。在shell中执行`A|B`时，A进程和B进程都是shell父进程的子进程，不存在父子关系。

​	命名管道（named pipe）：去除了管道（pipe）只能在父子进程中使用的限制，命名管道与文件系统共享一个名字空间，可以从文件系统中看到命名管道，常用于客户-服务应用程序中，命名管道用作客户端汇聚点。涉及到的命令是`mkfifo`，在文件系统中以文件形式存在，类型为`p`，通信数据遵循FIFO。

=> 对于管道通信，进程写入数据缓存在内核中，另一个进程读取也是从内核中读取，效率较低，随进程创建而创建，随进程消亡而消亡，不适合进程间频繁交换数据。

​	消息队列（message queue）：独立于读写进程而存在，任何有权限的进程都可以读写，支持多个进程，不需要进程自己提供同步方法，读进程可以根据消息类型选择性接收消息，但**通信不及时、大小受限（内核中每个消息体有一个最大长度限制，所有消息体总长度也有限制）、用户态和内核态的拷贝开销**。**消息队列是保存在内核中的消息链表**，发送数据时会分成一个一个独立数据单元即消息体（用户自定义的数据类型，发送方和接收方事先约定），进程从消息队列中读取消息体，内核就会将相应的消息体删除，生命周期跟随内核，如果没有释放则消息队列一直存在。

​	共享内存（shared memory）：**为了解决消息队列存在用户态和内核态数据拷贝的开销**，拿出一块虚拟空间映射到相同的物理内存中，速度最快，**通常需要使用信号量互斥访问**。不同于管道的地方是，**共享内存通信双方必须在同一台物理机器上**，而且访问方式是随机的，而非一端写一端读。使用全局变量在同一进程的进程间实现通信通常不称为共享内存

​	信号量（semaphore）：**为了解决多进程共享内存时同时修改的冲突，防止多进程共享资源，造成数据错乱**，引入信号量，本质上一个整型的计数器，用于多个进程提供对共享数据对象的访问，可用于**实现进程间的互斥和同步，而非缓存进程间通信的数据**。当初始化为1时，就代表互斥信号量；当初始化为0时，就代表同步信号量，可用于进程同步。

​	信号（signal）：为了解决异常模式下的工作模式，引入**信号**通知进程，与信号量不同，唯一的异步通信机制，用于通知接受进程某事件已经发生，传输信息量小（使用管道或套接字不划算而且不想建立连接，并需要对方立即作出回应），在Linux中，为了响应各种各样的事件，提供了几十种信号，分别代表不同含义，可以通过`kill -l`查看。
​	其中`CTRL+C`产生`SIGINT`信号，表示终止该进程，`CTRL+Z`产生`SIGSTOP`信号，表示停止该进程但未结束，`kill -9 [pid]`给指定进程发送`SIGKILL`信号用于立即结束该进程。
​	用户进程对信号的处理方式有：（1）执行系统为信号规定的默认操作，（2）捕捉信号，自定义一个信号处理函数，当信号发生时，执行响应的信号处理函数，（3）忽略信号
​	**【注意】`SIGKILL`和`SIGSTOP`信号是无法捕捉和忽略的**，用于在任何时候中断或结束某一进程

​	Socket：可以实现跨网络与不同主机进程通信，也可以用于同主机上进程通信，系统调用是`int socket(int domain,int type,int protocal)`，domain用于指定协议族（AF_INET用于IPv4，AF_INET6用于IPv6，AF_LOCAL/AF_UNIX用于本机），type用语指定通信特性（SOCK_STREAM字节流，SOCK_DGRAM数据报，SOCK_RAW原始套接字），protocal指定通信协议（基本已废弃，一般写0），根据socket类型根据参数而确定

针对TCP协议通信的socket编程模型

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdrci5jbi1iai51ZmlsZW9zLmNvbS9iMDU3MmRkOS03YTI1LTQ0OTUtOWIyZS0wZTg1NjM0MTg1ZTMucG5n?x-oss-process=image/format,png)

针对UDP协议通信的socket编程模型

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdrci5jbi1iai51ZmlsZW9zLmNvbS82NTRjY2Y3NC02MWJkLTQ3OTItYWNlZi1jYWI3ZWUwZGM5YzkucG5n?x-oss-process=image/format,png)

针对本地通信的socket编程模型

本地 socket 被用于在同一台主机上进程间通信的场景：

本地 socket 的编程接口和 IPv4 、IPv6 套接字编程接口是一致的，可以支持「字节流」和「数据报」两种协议；
本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现；
对于本地字节流 socket，其 socket 类型是 AF_LOCAL 和 SOCK_STREAM。

对于本地数据报 socket，其 socket 类型是 AF_LOCAL 和 SOCK_DGRAM。

本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别。

参考资料：https://blog.csdn.net/qq_34827674/article/details/107678226?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.no_search_link

**线程通信**

​	共享进程的资源，全局变量

#### （5）进程、线程、协程

进程：资源分配的基本单位，独立运行的基本单位，包括PCB、程序段和数据段，切换代价大（因为TLB会失效等 ）

线程：调度的基本单位，独立的寄存器组、指令计数器、处理器状态，与同一进程下线程共享地址空间

协程：线程创建的执行体，只能分配用户栈，也称为”用户态线程”，思想关键在于控制流的主动让出和恢复，每个协程拥有自己的协程栈，可以保存自己的执行现场。

区别：

（1）从属关系，独立性，通信方式，相互之间

（2）进程同步方法：互斥锁、读写锁、条件变量、记录锁、信号量、屏障
		  线程同步方法：互斥锁、读写锁、条件变量、信号量、自旋锁、屏障

虚拟地址空间被划分为内核空间和用户空间。

进程控制信息在内核空间中，包括页目录、ID、父进程ID、状态、打开文件句柄表，线程是进程中的执行体，要有指定的执行入口。 

线程控制信息在内核空间中，包括执行入口、线程栈（操作系统会分配两段栈--用户栈和内核栈，线程切换到内核态运行时会切换到内核栈，为了不允许用户代码对齐进行修改保护安全）、线程ID等。

当需要执行某个线程时，IP指向该线程的执行入口，栈基和栈指针寄存器会记录用户栈的位置【这意味着程序执行时CPU面向的是某个线程，所以说线程是操作系统调度和执行的基本单位】

一个进程中至少要有一个线程 -- 主线程，一般是有父进程或操作系统创建的，其他线程一般是由主线程创建的，线程发生函数调用时则在线程栈中分配函数调用栈，线程调用系统服务（虚拟内存分配、文件操作、网络读写等）时通过**系统调用**（最初是软中断--通过指令模拟中断，系统调用表+中断向量表，后来改为通过特殊指令触发 ，从专用寄存器拿派发入口地址，省去查询中断向量表的过程）来完成。

线程切换：保存当前线程执行现场如指令指针、栈指针等寄存器的值，修改为切换线程的寄存器值，内存中调度相关的数据结构

进程切换：CPU保存的页目录地址要修改为切换进程的页目录地址，会导致地址空间等进程资源发生变化，会导致TLB缓存失效

协程与IO多路复用：
IO多路复用会涉及到socket，而socket操作都有操作系统来提供，进程控制信息中会保存socket文件句柄，每个TCP socket创建时OS都会为其分配一个读缓冲区和写缓冲区（在内核空间中，需要完成拷贝到用户空间的操作）。
当出现没有数据可以读或者写缓冲区满时，怎么处理：
（1）阻塞式IO -- 让出CPU，进入等待队列，处理一个socket就要一个线程，在高并发场景下会加剧调度开销
（2）非阻塞式IO -- 不让出CPU，频繁检查socker是否就绪，容易造成空耗CPU，加剧延迟
（3）IO多路复用 -- 由操作系统提供支持，将需要等待的socket加入监听集合，通过一次系统调用，同时监听多个socket
		【1】select：每次都要传入所有监听集合，需要频繁从用户态到内核态拷贝数据，就绪时也需要遍历
		【2】poll： 监听数目等于可打开的文件符个数
		【3】epoll：
（4）信号驱动：通知来取
（5）异步I/O：直接快递

总体来看 -- 就绪时需要恢复现场，陷入等待时需要保存现场   -> 协程很适合

#### （6）死锁

条件：互斥资源有限、不可抢占、占有并请求、循环等待

解决方案：

- （1）检测与恢复 -- 检查时资源分配矩阵，资源等待矩阵，系统当前可用总量；恢复时可采用抢占！杀死！回滚！
- （2）不让死锁发生
  - 避免死锁（动态）：银行家算法-- 在分配前确保资源分配后不会进入不安全状态（死锁或潜在死锁）
  - 消除必要条件（静态）：增加资源（破坏资源有限，不现实）、资源一次性分配（破坏保持并请求，资源利用率不高）、可抢占资源（破坏不可抢占）、资源有序分配（破坏循环等待，定义资源请求顺序）

#### （7）缓存穿透、缓存击穿、缓存雪崩

缓存穿透：缓存和数据库中都没有的数据，可能属于攻击，可以通过校验或缓存空值或布隆过滤器防范

缓存击穿：缓存中没有但数据库中有的数据，由于并发用户多且访问同一数据，同时缓存中没有读到，导致数据库压力瞬间增大，可以通过设置热点数据永不过期和互斥锁来防范

缓存雪崩：缓存中数据大批量到了过期时间，而查询数量巨大，引起数据库压力过大甚至宕机，可以通过设置随机过期时间+热点数据均匀分布+永不过期来防范

#### （8）进程调度

可以调度：

* 当前进程运行结束
* 当前进程阻塞
* 系统调用后返回用户进程
* 抢占式+高优先级
* 时间片耗尽

不可调度：

* 中断程序处理
* 内核程序临界区
* 屏蔽中断的原子操作过程中

调度策略：

FCFS、SJF、优先级调度、时间片轮转、高响应比、多级队列、多级反馈队列

#### （9）同步的本质

实现临界区操作的互斥性，单核状态下，借助硬件指令（Compare And Swap、Fecth And Add、Test And Set等）实现锁机制，但在多核状态下，仅依靠硬件指令是不够的，需要借助总线锁（一旦使用了总线锁，则从并行变成了串行），而当前的缓存机制使得为了保证多核间高速缓存的一致性，引入了MESI协议（高速缓存一致性协议）

#### （10） 进程创建

- 分配进程控制块
  - 进程基本信息指针（进程ID、创建用户ID、创建时间等）
  - 进程家族树指针（子进程、父进程、孙子进程、祖父进程）
  - 信号支持
  - 进程状态信息指针（程序寄存器、状态字、优先级等）
  - 时间统计信息（所占CPU时间、子进程所占CPU时间等）
  - 其他需要的信息指针...
- 初始化机器寄存器
- 初始化页表
- 将程序代码从磁盘读进内存
- 将处理器状态设置为“用户态”
- 跳转到程序的起始地址（设置程序计数器）

最后两步借助硬件作为一个步骤一起完成



#### （11）进程调度

- 因时序或外部中断或进程挂起导致系统获得CPU控制权
- 操作系统在所有就绪进程中按照某个算法遴选进程
- 如果选中的是非当前进程，则操作系统将当前进程状态予以保护
- 为选中的进程布置环境（寄存器、栈指针、状态字等）
- 跳转到选中的进程



#### （12） 线程资源

共享资源：地址空间、全局变量、打开的文件、子进程、计时器、信号和信号服务程序、记账信息

独享资源：程序计数器、寄存器、栈、状态字



#### （13） 锁机制 -- 线程同步

```c++
// 故事：Alice和Bob喂鱼，一天内只能且必须有一个人喂鱼，否则鱼会胀死或饿死
// ====  朴素思想，没喂则喂一次
// == alice
if (noFeed) {
  feed
}
// == bob
if (noFeed) {
  feed
}
// 【问题】：线程的执行顺序是未知的，所以鱼可能会胀死
// 引入互斥 -- 不能由两个进程同时进入临界区，进程能正确执行，互斥区域外不能阻止另一个进程的运行，不能无限等待
// ==== 互斥喂，通过交谈（留下纸条）
// == alice
if (noNote){
  leave note;
  if (noFeed){
    feed;
  }
  remove note
}
// == bob
if (noNote){
  leave note;
  if (noFeed){
    feed;
  }
  remove note
}
// 【问题】：线程的执行顺序是未知的，所以鱼还是可能会胀死，因为留下纸条并没有达到互斥的目的（先检查再留字条），但降低了胀死的概率
// 防止同时进入临界区 -- 先留自己的字条，再检查对方的字条
// == alice
leave noteAlice;
if (noNoteBob){
  if (noFeed){
    feed;
  }
  remove note
}
// == bob
leave noteBob;
if (noNoteAlice){
  if (noFeed){
    feed;
  }
  remove note
}
// 【问题】：两个可能都留了纸条但还没来得及喂鱼，此时存在鱼会饿死的可能性
// ==== 确认有人喂了鱼才离去
// == alice
leave noteAlice;
while (noNoteBob){
  do nothing;
}
if (noFeed){
   feed;
}
remove note;
// == bob
leave noteBob;
if (noNoteAlice){
  if (noFeed){
    feed;
  }
}
remove note;
// 【问题】：程序不对称+CPU浪费
// ==== 借助锁
// == alice
lock(); // 等待锁打开，获得锁并锁上
if (noFeed){
    feed;
}
unlock(); // 打开锁
// == bob
lock();
if (noFeed){
    feed;
}
unlock();
// 【问题】：等待的人会一直在做无效等待
// ==== 减小临界区代码
// == alice
lock(); // 等待锁打开，获得锁并锁上
if (noNoteBob)
  leave noteAlice
unlock();
if (noNoteBob){
  if (noFeed){
    feed;
	}
}

// == bob
lock(); // 等待锁打开，获得锁并锁上
if (noteAlice)
  leave noNoteBob
unlock();
if (noNoteAlice){
  if (noFeed){
    feed;
	}
}
// 【问题】还是会有忙等的时间，借助sleep和wake up
// 引入生产者-消费者问题
// 解决两个问题：
// （1）检查count时唤醒对方，可能没有sleep的对方
// （2）对count变量的修改可能会发生数据竞争
// 引入信号量：叫醒信号保留，将信号积累起来操作系统原语
// 三个信号量：一个二元信号量用于互斥，另两个信号量分别用于唤醒对方
const int N=100;
typedef int semaphore;
semaphre mutex=1;
semaphore empty=N;
semaphore full=0;
void producer() {
  int item;
  while(True){
    item=produce_item();
    down(empty);
    down(mutex);
    insert_item(item);
    up(mutex);
    up(full);
  }
}
void consumer() {
  int item;
  while(True){
    down(full);
    down(mutex);
    remove_item(item);
    up(mutex);
    up(full);
  }
}
// 【问题】：如果将两个down颠倒，会产生死锁，颠倒两个up不会改变正确性，但会导致程序效率下降
// 引入管程 = 锁 + 条件变量（线程可以在上面等待的东西，另一个线程可以发送信号将在条件变量上的线程唤醒）
// 中心思想：在管程内睡觉的线程，睡前将进入管程的锁或信号量释放。
// 管程的问题：对编译器的依赖；网络环境下进行同步需要引入其他机制 -- 消息传递
// 消息传递是通过 同步双方经过互相发送消息来实现，有两个系统调用（可以是阻塞调用也可以是非阻塞调用），同步需要的是阻塞调用。
```

原子操作：不可被中断的一个或多个系列操作
每个CAS操作过程包含三个量：内存地址、期望值、新值
基本思路：如果地址上的值和期望值相等，则给其赋予新值，否则不做任何事情，而只返回原值是多少
处理器实现：总线加锁/缓存加锁/

#### （14）文件系统

| 主引导记录 | 分区表 | 分区1（主分区） | 分区2 | 分区3 | ...  | 分区n |
| :--------: | :----: | :-------------: | :---: | :---: | :--: | :---: |

​																	                 	/															\	

| 引导记录 | 超级数据块 | 闲置空间管理 | I-NODE区 | 根目录区 | 文件和目录区 |
| :------: | :------: | :------: | :------: | :------: | :------: |

一个磁盘包括一个个扇面，从0开始编号，0号扇面存放的是主引导记录（MBR）【一个小小的程序，用来启动计算机】，紧跟着磁盘分区表（磁盘的所有分区及其开始和结束地址）【其中一个分区为主分区，操作系统装载在此分区，主分区中最前面的是引导记录（Boot Record）】，在引导记录块后的内容因情况而异，一般是一个超级数据块（Super Block）【存放文件系统的各种参数如文件新系统类型、文件系统数据块尺寸等】，在超级数据块之后则是磁盘自由空间，后面是I-NODE区，再往后是文件系统根目录区，分区最后存放的是用户文件和文件夹区。

**引导记录**：一个小程序，负责找到操作系统映像，并加载到内存，从而启动操作系统

计算机启动时，主板ROM中的BIOS程序首先运行，进行基本的系统配置扫描后对磁盘的0号扇面进行读操作，将主引导记录（MBR）中的程序读入内存并运行，MBR程序接下来找到主分区，并将主分区里面的引导记录加载并运行。



文件的数据结构中有一个存放文件数据指针的表（文件分配表）

索引文件组织：将所有文件的所有数据块的磁盘地址收集起来，集中放在一个索引数据块里，文件打开时将该数据块加载到内存。即I-NODE（文件的逻辑数据块号 -- 对应的物理磁盘数据块编号）



Linux中会为每个文件分配两个数据结构：索引节点和目录项，主要用于记录文件的元信息和目录层次结构。

- 索引节点：即inode，用于记录文件元信息如inode编号、文件大小、访问权限、创建时间、修改时间、磁盘位置等，是文件的唯一标识。
- 目录项：即dentry，用来记录文件名、索引节点指针以及其他目录项的层级关系。多个目录项关联起来形成目录结构，目录项是由内核维护的维护的数据结构，不存放于磁盘，而是缓存于内存。

索引节点唯一标识一个文件，而目录项记录文件名，所以目录项与索引节点是多对一的关系即一个文件可以有多个别名【硬链接实现就是多个目录项的索引节点指向同一个文件】

目录也是文件，也是用索引节点唯一标识，和普通文件的区别是目录文件在磁盘中保存子目录或文件，而普通文件在磁盘中保存的是文件数据。



硬盘格式化时会被分为三个存储区域

- 超级块

  存储文件系统的详细信息如块大小、块个数、空闲块等

  当文件系统挂载时进入内存

- 索引节点区

  存储索引节点

  当文件被访问时进入内存

- 数据块区

  存储文件或目录数据

#### （15）虚拟内存 vs 文件缓存

一部分程序（文件）处于内存、一部分程序（文件）处于磁盘

虚拟内存的根本目的：提供一个速度非常快、容量非常大的并不存在的内存空间，从物理内存出发，为了增加内存空间而扩展到磁盘上。

文件缓存的根本目的：提高文件的访问效率，从磁盘出发，为了提高访问效率而将文件置于缓存



#### （16） DHCP

基于UDP，主要过程：

- 客户端广播DHCP Discover报文（服务器的IP地址对于客户端来说是未知的，所以用广播）
- 所有的DHCP服务器回应DHCP Offer报文（此时客户端知道服务器的IP了，其中也提供了一个合适的IP及租约、网关等配置信息，在选择合适IP时，会确认锁分配的IP没有被其他设备所使用，通过ICMP报文进行探测数次，如果都没有收到应答则说明IP可用）
- 客户端广播DHCP Request报文（一般针对第一个Offer报文，采用广播的原因是通知所有的DHCP服务器客户端的选择，以让其他服务器收回曾提供的IP）
- 服务器回应DHCP ACK报文（根据MAC地址查询有没有租约记录，如果有则发送ACK报文，在客户端收到ACK后，广播发送ARP报文探测是否有主机使用服务器分配的IP地址，否则发送DECLINE报文给服务器，通知服务器提供的IP地址不可用，并重新申请；否则发送NAK报文作为应答以告知无法分配合适的IP地址，此时客户端重新申请）
- 租约到期时，客户端发送DHCP Release报文释放IP地址



#### （17）边际网关协议BGP vs 开放式最短路径优先协议（OSPF）

BGP：实现自治系统（AS）之间路由可达，并选择最佳路由的距离矢量路由协议

OSPF：内部网关协议，单一自治系统内决策路由



#### （18）向操作系统申请内存

涉及两个系统调用：brk和mmap

brk: 将进程数据段的最高地址指针向高处移动，可以扩大进程在运行时的堆大小

mmap:将进程虚拟空间中寻找一块空闲的虚拟内存，获得一块可以操作的堆内存

其中brk用于分配小于128k的内存，mmap用于申请大于128k的内存

进程先通过系统调用获取或扩大进程的虚拟内存，获取虚拟地址

直到访问这些虚拟地址时产生缺页中断，分配物理页，内存分配才算完成





#### （18） 信号 vs 中断

信号：每个信号对应一个正整数常量，代表同一用户的诸多进程之间传送事先约定的信息类型，用于通知某进程发生了某异常事件。每个进程在运行时都要通过信号机制来检查是否有信号到达，若有则中断当前程序，转去处理该信号对应的处理程序，以完成对该事件的处理，处理结束后再返回到原来的断点继续执行。

二者相似点：

- 相同的异步通信方式，检测到信号或中断请求时都暂停当前程序，转去处理相应的处理程序，并在处理完毕后返回原来的断点
- 都可以对信号、中断进行屏蔽

二者不同点：

- 中断具有优先级，而信号平等
- 信号处理程序是在用户态下运行的，而中断处理程序是在内核态运行 
- 中断响应是及时的，而信号响应通常有较大时间延迟

信号机制的用途/功能：

- 发送信号，使用系统调用kill实现
- 预置对信号的处理方式，接受信号的程序用signal()来实现对处理方式的预置
- 接受信号的程序按事先的规定完成相应事件的处理



#### （19）一个进程能创建多少线程？

- 系统位数（32or64）下的用户空间大小和创建线程分配的栈空间大小

- 内核参数
  - /proc/sys/kernel/threads-max，系统支持的最大线程数，默认14553
  - /proc/sys/kernel/pid_max，系统全局PID号数值限制，默认32768
  - /proc/sys/vm/max_map_count，限制一个进程可以拥有的VMA（虚拟内存区域）的数量，默认65530



#### (20) CPU缓存一致性

在不同核上的两个线程对同一个变量进行操作，由于缓存策略的问题，某一个线程修改了变量但并未写会内存，此时另一个线程尝试从内存中读取，导致执行结果错误，这就是所谓缓存一致性问题。

解决机制：

- 某个核上对Cache数据的更新，**必须**传播到其他核心的Cache，称之为**写传播**
- 某个核上对数据的操作顺序，**必须**在其他核看来顺序是一样的，称之为**事务的串形化**【解释：由于不同核对数据进行同时修改，进行写传播时由于随机性的结果导致收到的顺序不一样，进而导致其他核上缓存中数据不一致】
  - 核对于Cache中数据的操作，需要同步给其他核
  - 引入锁机制，只有拿到锁才能更新

通过**总线嗅探**等方式将更新传递给其他核，此时每个核都要监听总线上的一切活动而不管其他核是否缓存了相同数据，而且并未实现事务串形化。**MESI**协议做到了CPU缓存一致性

**MESI协议** ： Modified（已修改）、Exclusive（独占）、Shared（共享）、Invalidated（已失效）标记缓存块的不同状态，其中独占核共享状态表示缓存块中数据时一致的，差别在于独占状态下数据只存储在一个核心的缓存中，可以自由写入，但如果其他核从内存中读取了相同的数据，则独占状态下的数据就会变为共享状态；共享状态下的缓存中数据更新时不能直接修改，而是先向其他核广播请求--将对应的缓存行标记为无效状态，然后再更新当前核缓存中的数据。



#### （21）什么是Cache伪共享

两个核上的不同线程对同一个内存块进行缓存，但修改的数据不冲突，由于写回策略的问题，会持续交替分别修改相应变量，在MESI协议下，缓存也会持续交替失效的现象。

解决方案：

- Linux 内核中 `__cacheline_aligned_in_smp`宏定义用于解决伪共享问题，实质上将不同的变量进行“缓存块级别的对齐“
- Java并发框架Disruptor使用【字节填充+继承】的方式避免伪共享问题



#### （22）忙等锁（自旋锁）/无忙等锁的基本实现

忙等锁/自旋锁

```c++
typedef struct lock_t{
  int flag;
}lock_t;
void init(lock_t *lock){
  lock->flag=0;
}
void lock(lock_t *lock){
  while(TestAndSet(&lock->flag,1)==1){
    // do nothing
  }
}
void unlock(lock_t *lock){
  lock->flag=0;
}
```

无忙等锁

```c++
typedef struct lock_t{
  int flag;
  queue_t *q; // 等待队列
}lock_t;
void init(lock_t *lock){
  lock->flag=0;
  queue_init(lokc->q);
}
void lock(lock_t *lock){
  while(TestAndSet(&lock->flag,1) == 1){
    // 保存当前线程TCB
    // 将当前线程TCB插入等待队列
    // 设置当前线程为等待状态
    // 执行调度程序
  }
}
void unlock(lock_t *lock){
  if(lock->q !=Null ){
    // 移出等待队列队首元素
    // 将该线程的TCB插入就绪队列
    // 设置该线程为就绪状态
  }
  lock->flag=0;
}
```



#### （23）读者-写者问题



- 读者优先，写者可能处于饥饿状态

  ```c++
  semaphore wMutex; // 初始值为1，控制写操作的互斥信号量
  semaphore rCountMutex; // 初始值为1，控制rCount的修改
  int rCount = 0; // 初始值为0
  void writer(){
    while(TRUE){
      P(wMutex);
      write();
      V(wMutex);
    }
  }
  void reader(){
    while(TRUE){
      P(rCountMutex);
      if (rCount == 0) {
        P(wMutex); // 阻塞写者
      }
      rCount++;
      V(rCountMutex);
      
      read();
      
      P(rCountMutex);
      rCount--;
      // 最后一个读者离开，唤醒写者
      if ( rCount  == 0 ){
        V(wMutex);
      }
      V(rCountMutex);
    }
  }
  
  ```

- 写者优先，只要有写者准备写入，则后来的读者要阻塞，当然，读者可能会饥饿

  ```c++
  semaphore rCountMutex; // 初始值为1，控制rCount的修改
  semaphore rMutex; // 初始值为1，控制读者进入的互斥信号量
  
  semaphore wCountMutex; // 初始值为1，控制wCount的修改
  semaphore wDataMutex; // 初始值为1，空着写着写操作的互斥信号量
  
  int rCount=0;
  int wCount=0;
  
  void writer(){
    while(TRUE){
      P(wCountMutex);
      if (wCount ==0 ){
        P(rMutex); //阻塞读者
      }
      wCount++;
      V(wCountMutex);
      
      P(wDataMutex);
      write();
      V(wDataMutex);
      
      P(wCountMutex);
      wCount--;
      if (wCount == 0){
        V(rMutex); //最后一个写者离开，唤醒读者
      }
      V(wCountMutex);
    }
  }
  void reader(){
    while(TRUE){
      P(rMutex);
      P(rCountMutex);
      if (rCount == 0){
        P(wDataMutex); // 阻塞写者
      }
      rCount++;
      V(rCountMutex);
      V(rMutex);
      
      read();
      
      P(rCountMutex);
      rCount--;
      if (rCount == 0){
        V(wDataMutex); // 最后一个读者离开，唤醒写者
      }
      V(rCountMutex);
    }
  }
  ```

- 公平策略

  ```c++
  semaphore rCountMutex; // 初始值为1，控制rCount修改
  semaphore wDataMutex; // 初始值为1，控制写者写操作
  semaphore flag; // 初始值为1，用于实现公平竞争
  int rCount = 0;
  void writer(){
    while(TRUE){
      P(flag); // 不让后来的读者直接进入，而是在那里等待以实现公平
      P(wDataMutex);
      write();
      V(wDataMutex);
      V(flag);
    }
  }
  void reader(){
    while(TRUE){
      P(flag);
      P(rCountMutex);
      if (rCount == 0){
        P(wDataMutex);
      }
      rCount++;
      V(rCountMutex);
      V(flag);
      
      read();
      
      P(rCountMutex);
      rCount--;
      if (rCount == 0){
        V(wDataMutex);
      }
      V(rCountMutex);
    }
  }
  ```

#### （24）锁

如果能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该用自旋锁。反之则应该用互斥锁。

- 互斥锁

  最底层的锁之一，加锁失败后，线程释放CPU，会从用户态陷入内核态，由操作系统内核实现

- 自旋锁

  最底层的锁之一，加锁失败后，会忙等，直到拿到CPU，通过CPU提供的CAS原子操作，在用户态完成加锁和解锁操作，不会主动产生线程上下文切换。

  最好使用CPU提供的PAUSE指令来实现忙等待，可以减少循环等待时的耗电量。

  单核下需要抢占式的调度器，否则自旋锁在单CPU无法使用，因为一个自旋的线程永远不会放弃CPU。

- 读写锁

  由读锁和写锁两部分组成，如果只读取则用读锁加锁，如果修改共享资源则用写锁加锁。

  适用于能明确区分读操作和写操作的场景。

  工作原理：

  - 没有线程拥有写锁时，多个线程可以并发地持有读锁，大大提高了共享资源的访问效率。
  - 一旦有线程拥有写锁，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。

  根据实现的不同，可以分为读优先锁和写优先锁。

  - 读优先锁：当读线程A先持有了读锁，写线程B在获取写锁时，会被阻塞，并在阻塞过程中，读线程C可以成功获取读锁，直到所有的读线程都释放读锁后，写线程B才能获取写锁。
  - 写优先锁：当读线程A先持有了读锁，写线程B在获取写锁时，会被阻塞，并在阻塞过程中，读线程C获取读锁时会失败，于是读线程C将被阻塞在获取读锁的操作，只有当读线程A释放读锁后，写线程B才能成功获取写锁。
  - 公平读写锁：用队列把获取锁的线程排队，不管是写线程还是读线程，都按照先进先出的原则加锁即可，这样读线程仍旧可以并发也不会出现饥饿。

- 悲观锁

  认为多线程同时修改共享资源的概率比较高，容易出现冲突，

  工作方式：访问共享资源前，先要上锁。

- 乐观锁

  假定多线程同时修改共享资源的概率比较低，冲突的概率低。

  工作方式：先修改共享资源，再验证这段时间内有没有发生冲突，如果没有则操作完成，否则放弃本次操作。

  缺点是一旦发生冲突，重试的成本非常高，所以一般只有在冲突概率非常低，且加锁成本非常高的场景中才考虑使用。

​	

#### （25） 硬链接 vs 软链接

硬链接：多个目录项的索引节点指向一个文件（同一个inode），但不可跨文件系统（因为每个文件系统都有各自的inode数据结构和列表），只有删除所有的硬链接及源文件，系统才删除。

软链接：特殊的文件，有独立的inode，文件内容是另一个文件的路径，可以跨文件系统，甚至目标文件被删除了，链接文件还是在的。



#### （26）缓冲/非缓冲 I/O vs 直接/非直接 I/O vs 阻塞/非阻塞 I/O vs 同步/异步 I/O

缓冲I/O：利用标准库的缓存实现文件的加速访问，而标准库再通过系统调用访问文件

非缓冲I/O：直接通过系统调用访问文件，不经过标准库缓存

直接I/O：不发生内核缓存和用户程序之间的数据复制，而是直接通过文件系统访问磁盘。需要在使用文件系统类系统调用时指定`O_DIRECT`标志位。

非直接I/O：读操作时，数据从内核缓存中拷贝给应用程序，写操作时，数据从用户程序拷贝给内核缓存，再有内核决定什么时候写入数据到磁盘。文件系统类的系统调用的默认设置。

阻塞I/O：当用户程序执行read时，线程被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序缓冲区，拷贝完成时，read才会返回。【等待着**内核准备好数据**和**数据从内核态拷贝到用户态**】。访问管道或socket时的默认行为。

![clipboard.png](https://segmentfault.com/img/bVm1c3)

非阻塞式I/O：非阻塞的read请求在数据未准备好时立即返回，可以继续往下执行，此时应用程序**不断轮询内核，直到数据准备好，内核将数据拷贝到应用缓冲区，read调用才返回结果。**【等待着**内核态数据拷贝到用户态**】。访问管道或socket时需要设置`O_NONBLOCK`标志位。

![clipboard.png](https://segmentfault.com/img/bVm1c4)

为了解决“傻乎乎”的轮询方式，引入了**I/O多路复用**：通过I/O事件分发，当内核数据准备好时再通知应用程序进行操作。select/poll的优势不是对于单个连接的处理更快而是能同时处理多个连接。



- select：阻塞系统调用，直到数据准备好，然后通知用户进程数据可读，再由用户进程发出read系统调用，等待数据拷贝完成，再通知用户进程处理数据。

  ```c++
  int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
  ```

  

  ![clipboard.png](https://segmentfault.com/img/bVm1c5)

  通过设置或检查存放的fd标志位的数据结构来进行处理，但单个进程可监视的fd数目是有限的（一般与系统内存有关关，/proc/sys/fs/file-namx查看，32位下默认1024，64位下默认2048），采用的扫描方式是线性扫描，时间复杂度为O(n)。

  每次调用select，都需要将fd集合从用户态拷贝到内核态，同时也需要在内核态中遍历（扫描）传递进来的fd，在fd很多时开销会很大。并且需要一个用来存放大量fd的数据结构，这个结构在从用户态到内核态传递也会有复制开销。

- poll：本质上与select没有区别，将用户传入的fd数组拷贝到内核，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有的fd没有发现就绪设备，则挂起当前进程，直到超时或设备就绪。

  ```c++
  int poll (struct pollfd *fds, unsigned int nfds, int timeout);
  struct pollfd {
      int fd; /* file descriptor */
      short events; /* requested events to watch */
      short revents; /* returned events witnessed */
  };
  ```

  

  因为基于链表的存储而解决最大连接数限制的问题。但因为每次被唤醒都要遍历所有的fd，同时大量的fd的数组要在内核态和用户态之间拷贝。

  还有一个特点是”水平触发“，报告了fd后，没有被处理，下次poll时会再次报告该fd。

- epoll：可以理解为event poll，不同于忙轮询和无差别轮询，会将**哪个流发生了怎么样的I/O事件通知**（每个事件上关联fd），复杂度降低为O(1)。

  有EPOLL LT（水平触发）和EPOLL ET（边缘触发）两种触发模式，LT是默认触发模式，只要这个fd还有数据可读，每次epoll_wait都会返回它的事件，提醒用户程序操作。但在ET模式下，只会提示一次，直到下次再有数据流入之前都不会再提示。

  **要有EPOLL ET的原因**：系统中一旦有大量不需要读写的就绪文件描述符，每次调用epoll_wait都会成功，大大降低处理程序检索自己关系的就绪文件描符的效率。而在ET模式下，如果被监控的文件描述符上有可读写事件发生，epoll_wait会通知处理程序去读写，如果这次没有全部处理完，下次epoll_wait也不会通知，效率高！

  只会管“活跃”的连接而无关连接总数，所以效率较select和poll都要高，同时利用mmap文件映射加速与内核空间的消息传递，减少了复制开销。理论支持的fd上限是最大可以打开文件的数目。

  提供三个函数：

  ```C++
  int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大
  int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；// 注册文件描述符，一旦基于某个文件描述符就绪时，内核会采用callback的方式迅速激活该文件描述符，当进程调用epoll_wait时就会收到通知
  int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
  ```

  - epoll_create：创建一个epoll句柄
  - epoll_ctl：注册要监听的事件类型，每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD）会把所有的fd拷贝进内核，而不是在epoll_wait时重复拷贝，保证每个fd在整个过程中只会拷贝一次。在epoll_ctl时把current挂一遍并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者是就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪列表
  - epoll_wait：等待事件的发生，在就绪列表中查看有没有就绪的fd，利用schedule_timeout实现睡一会判断一会的效果

在连接数少并且连接十分活跃的情况下，select和poll的性能可能比epoll要好（回调函数）。

同步I/O：阻塞I/O、非阻塞I/O、基于非阻塞I/O的多路复用

异步I/O：内核数据准备好、数据从内核态拷贝到用户态这两个过程都不用等待。aio_read之后立即返回，内核自动将数据从内核空间拷贝到应用程序空间，这个拷贝过程同样异步，由内核自动完成而无需应用程序主动发起拷贝动作。

![clipboard.png](https://segmentfault.com/img/bVm1c8)



参考资料：https://www.cnblogs.com/Anker/archive/2013/08/14/3258674.html

#### （27）文件描述符

在形式上是一个非负整数，实际山是一个索引值，指向内核为每一个进程所维护的该进程打开的文件的记录表中的某一个记录。

当程序打开或创建一个文件时，内核向该进程返回一个文件描述符。



#### （28）中断

软中断：代码调用INT指令等触发的中断

硬中断：硬件通过中断控制器触发的中断

设备驱动程序中会及时响应控制器发来的中断请求，并根据中断类型调用响应的中断处理程序（设备驱动程序初始化时注册该设备的中断处理函数）



#### （29）一个应用程序对外发送一个文件至少需要拷贝多少次？

- 应用程序调用socket发送数据包接口，首先通过read系统调用读取文件，从磁盘到磁盘缓冲区，需要发生一次拷贝，如果采用直接I/O，此处不需要拷贝，如果采用非直接I/O，则此处要发生一次内核态与用户态的数据拷贝；然后socket层会将应用层数据拷贝到内核的socket发送缓冲区中，此处要发生一次拷贝。
- 网络协议栈从socket发送缓冲区中取出数据包，按照协议栈从上往下处理，分片号的网络包送至网络接口层，再放到发包队列中
- 网卡驱动程序通过DMA从发包队列读取网络包，将其放入网卡的队列中，此处发生一次拷贝，然后网卡将其发送出去。

中间经过转发等过程

- 网络包达到目的端，网卡发起硬件中断，执行网卡硬件中断处理喊出，从网卡队列（Ring buffer）中拷贝到内核struct sk_buff缓冲区中，然后按照网络协议栈逐层处理，在传输层确定socket，并将数据拷贝到socket的接收缓冲区
- 应用程序通过调用socket接口，从内核的socket接受缓冲区读取数据到应用层
- 应用程序对数据进行处理，将文件存放至磁盘上，如果采用直接I/O，则不需要拷贝，如果采用非直接I/O，则要发生一次用户态到内核态到拷贝，再由内核决定什么时候将数据写入磁盘，写入磁盘也会发生一次拷贝。

此处的分析并未考虑CPU Cache！



![截屏2021-10-13 12.46.34](/Users/ouyangshiyong/Library/Application Support/typora-user-images/截屏2021-10-13 12.46.34.png)

![截屏2021-10-13 12.48.23](/Users/ouyangshiyong/Library/Application Support/typora-user-images/截屏2021-10-13 12.48.23.png)

期间发生了4次用户态与内核态的上下文切换，一次read，一次write。

期间发生了4次数据拷贝，其中2次是DMA拷贝，2次是CPU拷贝。

其中：从内核读缓冲区拷贝到用户缓冲区，再从用户缓冲区拷贝到socket的缓冲区即两次CPU拷贝是没有必要的，因此用户缓冲区可以省去。

再者，可以通过【零拷贝技术】减少上下文切换和数据拷贝次数。

【零拷贝技术】的实现方式：

- mmap+write

  使用mmap替换read，直接把内核缓冲区里的数据映射到用户间

  ![截屏2021-10-13 12.53.42](/Users/ouyangshiyong/Library/Application Support/typora-user-images/截屏2021-10-13 12.53.42.png)

  此时需要4次上下文切换（因为系统调用还是2次），3次拷贝。

- sendfile

  专门发送文件的系统调用，函数原型如下

  ```c++
  #include<sys/socket.h>
  // out_fd 目的端文件描述符
  // in_fd 源端文件描述符
  // offset 源端偏移量
  // count 复制数据的长度
  // 返回值是实际复制的长度
  ssize_t sendfile(int out_fd,int in_fd,off_t *offset,size_t count);
  ```

  首先，可以用该系统调用代替read和write两个系统调用，减少1次系统调用则减少2次上下文切换

  其次，sendfile可以直接将内核缓冲区的数据拷贝到socket缓冲区中，不再拷贝到用户态，共3次拷贝

  ![截屏2021-10-13 12.58.20](/Users/ouyangshiyong/Library/Application Support/typora-user-images/截屏2021-10-13 12.58.20.png)

如果网卡支持SG-DMA技术，sendfile系统调用将使用如下过程：

- 通过DMA将磁盘上数据拷贝到内核缓冲区中
- 缓冲区描述符和数据长度传到socket缓冲区，网卡的SG-DMA控制器直接将内核缓冲区的数据拷贝到网卡缓冲区中

![截屏2021-10-13 12.46.34](/Users/ouyangshiyong/Library/Application Support/typora-user-images/截屏2021-10-13 12.46.34.png)

CPU不参与数据搬运，所有数据都由DMA完成。只需要2次上下文切换和2次数据拷贝，并且这2次数据拷贝不需要通过CPU而是通过DMA搬运完成。性能提升至少一倍。

**Kafka开源项目利用了零拷贝从而大幅提高了I/O效率，Nginx也支持零拷贝技术**

下面解释一下上面提到的【内核缓冲区】，实际上是磁盘高速缓存（PageCache），利用程序运行的局部性原理，使用PageCache缓存最近被访问的数据，读磁盘数据时，优先在PageCache中找，其次再从磁盘中读取。同时了为了降低机械硬盘的物理消耗时间，使用【预读】功能（利用的是空间局部性），但是在传输大文件（GB级）时，PageCache会不起作用，会浪费【预读】的一次DMA，造成性能降低。

针对大文件传输，通过异步I/O，因为它并未涉及PageCache（绕过PageCache的I/O其实就是直接I/O，使用PageCache的I/O则就是缓存I/O），其流程如下：

![截屏2021-10-13 13.07.43](/Users/ouyangshiyong/Library/Application Support/typora-user-images/截屏2021-10-13 13.07.43.png)



#### （30）Socket为什么要绑定IP地址和端口？

- 绑定端口：当内核收到报文，通过报文的端口号来找到响应的应用程序
- 绑定IP地址：同一台机器上可以有多张网卡，每个网卡都有对应的IP地址，绑定IP后，内核收到对应网卡的包才会转发给用户态处理。

在内核中socket以文件形式存在，有对应的文件描述符。

每⼀个进程都有⼀个数据结构 task_struct ，该结构体⾥有⼀个指向「⽂件描 述符数组」的成员指针。该数组⾥列出这个进程打开的所有⽂件的⽂件描述符。数组的下标是⽂件描述 符，是⼀个整数，⽽数组的内容是⼀个指针，指向内核中所有打开的⽂件的列表，也就是说内核可以通过 ⽂件描述符找到对应打开的⽂件。

每个文件都有一个inode，socket文件的inode指向内核中的socket结构，其中有发送队列和接收队列，队列中保存的是一个一个strcut sk_buff，用链表进行管理。

sk_buff可以表示各层数据包，应用层叫data，tcp层叫segment，ip层叫packet，数据链路层叫frame。只用一个结构体描述的原因是省去协议栈分层下解析数据带来的数据拷贝，而是通过指针逐步剥离/填充协议首部。



#### （31）为了服务更多的用户！

网络I/O模型：

多进程模型 -> 多线程模型->线程池的多线程模型

I/O多路复用下的线程池多线程模型：一个进程维护多个socket

---------















## 数据库

#### （1）三大范式

第一范式：表中所有字段值都是不可分解的原子值

第二范式：所有非主属性都完全依赖于主码

第三范式：所有非主属性对任何候选关键字都不存在传递依赖（即跟主键有直接关系）

#### (2) HAVING 和 WHERE 的差别

WHERE 在数据分组前进行过滤，排除的行不包括在分组中

HAVING 在数据分组后进行过滤

#### (3) ORDER BY 和 GROUP BY的区别

ORDER BY 排序产生的输出，任何列都可以使用

GROUP BY 用于分组行，但输出可能不是分组的顺序，只可能使用选择列或表达式列而且必须使用每个选择列表达式

#### (4) Mysql 中子句的顺序

```
SELECT xxx 
FROM table_x
WHERE
GROUP BY
HAVING
ORDER BY
LIMIT
OFFSET
```

#### （5）脏读、不可重复读、幻读、丢失修改

当多个事务并发执行时，可能会出现以下问题：

- 脏读：事务A更新了数据，但还没有提交，这时事务B读取到事务A更新后的数据，然后事务A回滚了，事务B读取到的数据就成为脏数据了。 
- 不可重复读：事务A对数据进行多次读取，事务B在事务A多次读取的过程中执行了更新操作并提交了，导致事务A多次读取到的数据并不一致。 
- 幻读：事务A在读取数据后，事务B向事务A读取的数据中插入了几条数据，事务A再次读取数据时发现多了几条数据，和之前读取的数据不一致。 
- 丢失修改：事务A和事务B都对同一个数据进行修改，事务A先修改，事务B随后修改，事务B的修改覆盖了事务A的修改。 

不可重复度和幻读看起来比较像，它们主要的区别是：在不可重复读中，发现数据不一致主要是数据被更新了。在幻读中，发现数据不一致主要是数据增多或者减少了。

数据库的隔离级别分别可以解决数据库的脏读、不可重复读、幻读等问题。

| 隔离级别 |  脏读  | 不可重复读 |  幻读  |
| :------: | :----: | :--------: | :----: |
| 未提交读 |  允许  |    允许    |  允许  |
|  提交读  | 不允许 |    允许    |  允许  |
| 可重复读 | 不允许 |   不允许   |  允许  |
|  串行化  | 不允许 |   不允许   | 不允许 |

**MySQL的默认隔离级别是可重复读。**

#### （6） 聚集索引 vs 非聚集索引

聚簇索引和非聚簇索引最主要的区别是**数据和索引是否分开存储**。

- 聚簇索引：将数据和索引放到一起存储，索引结构的叶子节点保留了数据行。 
- 非聚簇索引：将数据进和索引分开存储，索引叶子节点存储的是指向数据行的地址。 

在InnoDB存储引擎中，默认的索引为B+树索引，利用主键创建的索引为主索引，也是聚簇索引，在主索引之上创建的索引为辅助索引，也是非聚簇索引。为什么说辅助索引是在主索引之上创建的呢，因为辅助索引中的叶子节点存储的是主键。

在MyISAM存储引擎中，默认的索引也是B+树索引，但主索引和辅助索引都是非聚簇索引，也就是说索引结构的叶子节点存储的都是一个指向数据行的地址。并且使用辅助索引检索无需访问主键的索引。

#### （7） 慢查询优化

什么是慢查询：执行时间超过某个临界值的SQL语句

相关参数：slow_query_log是否开启、slow_query_log_file慢查询日志存储路径、slow_query_time阈值、log_output存储方式(FILE/TABLE)等

如何优化：

- 分析语句的执行计划，索引是否命中【是否扫描了太多行、是否返回了太多列、添加缓存、了解查询执行过程】
- 优化数据库结构
- 优化LIMIT分页

#### (8) CAS操作

三个基本操作数：内存地址、旧预期值、要修改的新值

重新尝试的操作：重新获取内存地址，并重新计算想要修改的值，这个操作被称为自旋

缺陷：自旋带来的CPU开销、不能保证代码块的原子性、存在“ABA”行为【加上版本号可以解决】

#### （9） STEAL 和 FORCE策略

![img](http://ww4.sinaimg.cn/large/7cc829d3jw1f3dre5heh5j20hm0acjt7.jpg)

第5步可能在提交之后完成，因为一旦发生崩溃，还有可能利用REDO日志恢复事务，即为NO-FORCE策略

可以采用FORCE策略（如第5步在提交之前必须完成）来降低恢复时的负载

数据是一步步的写入（STEAL策略）还是缓冲管理器需要等待提交命令一次性全部写入（NO-STEAL策略），取决于想要什么：快速写入但从UNDO日志中恢复缓慢还是快速恢复

STEAL/NO-FORCE -- 需要UNDO和REDO，性能高，但日志和恢复过程复杂

STEAL/FORCE -- 只需要UNDO

NO-STEAL/NO-FORCE：只需要REDO

NO_STEAL/FORCE：什么都不需要，性能最差而且需要巨大内存



## MySQL

#### （1）基本子句

```mysql
USE databse_name;

SELECT *
FROM customers
WHERE birth_date > '1990-01-01'  -- AND / OR / NOT / BETWEEN ... AND ... / IN / LIKE / REGEXP / IS NULL / IS NOT NULL 
ORDER BY fitst_name
LIMIT offset_value,3;

-- 内连接
SELECT *
FROM orders
JOIN customers ON orders.customer_id = customers.curstomer_id;

-- 跨数据库连接
SELECT *
FROM order_items oi
JOIN sql_inventory.products p ON io.product_id=p.product_id;

-- 自连接
SELECT *
FROM employees e
JOIN employee m ON e.reports_to=m.employee_id;

-- 多表连接
SELECT *
FROM orders o
JOIN customers c ON c.customer_id=c.customer_id
JOIN order_statuses os ON o.status=os.order_status_id 

-- 复合连接条件
SELECT *
FROM order_items oi
JOIN order_item_notes oin ON oi.order_id = oin.order_id AND oi.product_id=oin.product_id

-- 隐式连接
SELECT * 
FROM orders o, customers c  -- 没有where就变成了笛卡尔积
WHERE o.customer_id=c.customer_id;

-- 外连接
SELECT *
FROM customers c
LEFT JOIN orders o ON c.customers_id=o.customer_id -- LEFT JOIN会返回customers的所有记录，无论是否为空
ORDER BY c.customer_id

-- 多表外连接
SELECT *
FROM customers c
LEFT JOIN orders o ON c.customer_id=o.customer_id
LEFT JOIN shippers sh ON o.shipper_id=sh.shipper_id
ORDER BY c.customer_id

-- 自外连接
SELECT *
FROM employees e
JOIN employees m ON e.reports_to=m.empoyee_id

-- 如果两个表中列名称一致，可使用USING替代ON

-- 自然连接，不建议使用
SELECT *
FROM orders o
NATURAL JOIN customers c

-- 交叉连接
	-- 显式
SELECT *
FROM customers c
CROSS JOIN products p -- 两个表的每条记录都连接即笛卡尔积
	-- 隐式
SELECT *
FROM customers c, orders o

-- UNION
SELECT first_name
FROM customers
UNION
SELECT name
FROM shippers

-- INSERT
INSERT INTO customers
VALUES (DEFAULT,'John','Smith','1999-01-01',NULL,'address','city','CA',DEFAULT) -- DEFAULT 用于自增的列或有默认值的列，这种方式必须插入所有列

INSERT INTO customers (first_name,last_name,birth_date,address,city,state)
VALUES ('John','Smith','1999-01-01','address','city','CA')

INSERT INTO shippers (name)
VALUES ('shipper1'),('shipper2'),('shipper3')
```

#### （2）in和exist的区别

二者均用于子查询

- exist先外再内，in先内再外
- in在内外查询均会使用索引，而exist仅在内查询使用索引
- 如果子查询的结果集较大，外表较小时exist效率更高，而如果子查询结果较小，外表较大时in效率更高
- not exists 效率比 not in高，因为not in对内外表都进行了全表扫描，而not exists子查询可以用索引

#### （3）临时表

临时表分为内存临时表（使用MEMORY存储引擎）和磁盘临时表（使用MyISAM存储引擎）

使用场景：

- FROM子查询
- DISTINCT  + ORDER BY
- ORDER BY 与 GROUP BY的子句不一样时
- UNION

#### （4）分表分库策略

水平拆分：同一个表拆到不同的数据库（水平分库）或拆成多张小表（水平分表）

垂直拆分：不同的表拆到不同的数据库（垂直分库）或拆分字段到多个表（垂直分表）

分表分库后ID的处理方案即全局ID：

- UUID，本地生成，全局唯一不重复，但占用空间且不适合作为索引
- 自增ID，需要有一个专门生成主键的库，每次都要先插入一次然后获取一个ID再去写数据，实现简单但高并发性能受限

#### （5）not null

- null和空值不一样
- NULL影响函数统计，如COUNT不会统计在内
- B树不存储NULL，所以索引不到NULL（上面统计不到的原因）
- NOT IN 子句查询在有NULL值的情况下返回结果全是空值

#### （6）优化

- UNION 不如 UNION ALL效率高
- 尽量不要在WHERE子句中使用不等于判断（因为会全表扫描而不是使用索引）
- WHERE 和 ORDER BY 涉及的列考虑建立索引

#### （7）执行顺序

```
SELECT DISTINCT select_list
FROM left_table
LEFT JOIN right_table ON join_condition
WHERE where_condition
GROUP BY group_by_list
HAVING having_condition
ORDER BY order_by_condition

=>
FROM -> ON -> JOIN -> WHERE -> GROUP BY -> HAVING -> SELECT -> DISTINCT -> ORDER BY
```

#### （8）主从复制

原理：涉及到三个线程binlog线程、I/O线程、SQL线程

binlog线程：负责将主服务器的数据更改写入二进制文件

I/O线程：负责从主服务器上读取二进制文件，并写入从服务器的中继日志

SQL线程：负责读取中继日志，解析并在从服务器中重放

#### （9）读写分离

读写分离主要依赖于主从复制，主从复制为读写分离服务

一般而言，主服务器负责写，从服务器负责度，缓解锁的竞争

主从服务器可以使用不同的存储引擎，提升查询性能

增加冗余，提高可用性

#### （10）drop、truncate、delete区别：
delete删除一行，记录在日志；

truncate清空表数据，不记录日志（只记录释放）不能恢复，没有激活触发器，执行速度快（表和索引会恢复到原始大小、索引还在）

drop删除数据和表结构（全部释放）

####  （11）误操作快速回滚

#### （12）锁

- 全局锁：主要用于全库逻辑备份，缺点是如果数据库引擎不支持可重复读的隔离级别，则会造成业务停滞。

  ```mysql
  -- 使用
  flush tables with read lock
  -- 释放
  unlock tables 
  ```

- 表级锁

  - 表锁

    ```mysql
    -- 表级别的共享锁，读锁
    lock tables table_name read;
    -- 表级别的独占锁，写锁
    lock tables table_name write;
    -- 释放
    unlock tables
    ```

  - 元数据锁（MDL）

    作用：保证用户对表执行CRUD操作时，防止其他线程对表结构做变更

    ```mysql
    -- 无须显式使用，当对数据库表进行操作时，自动给相应表加上MDL
    -- 对一张表进行CRUD操作时，加MDL读锁
    -- 对一张表进行结构变更操作时，加MDL写锁
    -- 事务执行期间，MDL一直持有。事务提交后才释放
    ```

  - 意向锁

    目的是快速判断表里是否有记录被加锁

    在给表中某些记录加共享锁之前，需要在表级别加上意向共享锁

    在给表中某些记录加独占锁之前，需要在表级别加上意向独占锁

    **普通select语句不会加行级锁，利用MVCC实现一致性读（无锁操作）**

    ```mysql
    -- 先在表上加意向共享锁，然后对读取记录加独占锁
    select ... lock in share mode;
    -- 先在表上加意向独占锁，然后对读取记录加独占锁
    select ... for update;
    ```

    意向共享锁和意向独占锁是表级别锁，不会与行级的共享锁和独占锁冲突，而意向锁之间也不会发生冲突，**但会和共享表锁、独占表锁发生冲突**

  - AUTO-INC锁

    特殊的表锁机制，不是在一个事务提交后才释放，而是在执行完插入语句后就立即释放，插入数据时，会加一个表级别的AUTO-INC锁，然后为AUTO_INCREMENT修饰的字段赋值递增的值，等插入语句执行完成后，才把AUTO-INC锁释放。

    为了解决插入大量数据时带来的性能问题，引入一个**轻量级的锁**来实现自增，在插入数据时，会为被AUTO_INCREMENT修饰的字段加上轻量级锁，然后赋值，然后释放轻量级锁，而不需要等待整个插入语句执行完才释放。

    系统变量`innodb_autoinc_lock_mode`用于控制选择AUTO-INC锁还是轻量级锁，默认情况下两种锁混用（对插入的记录数目有阈值）

    为什么不一直直接使用轻量级锁？

    并发插入时，每次插入时的自增长的值可能不是连续的，这导致在有些主从复制场景中不安全。

- 行级锁

  - Record Lock

    锁住一条记录

  - Gap Lock

    锁定一个范围（前开后开区间），但不包含记录本身

  - Next-Key Lock

    锁的是索引，而不是数据本身，锁住一个范围（前开后闭区间），同时锁住记录本身。

    在某些场景下会退化为记录锁或间隙锁。

    - 唯一索引等值查询 --  查询记录存在时，退化为记录锁，查询记录不存在时，退化为间隙锁
    - 唯一索引范围查询 -- 范围查询时如果记录不存在会退化到末尾的间隙锁
    - 非唯一索引等值查询 --查询记录存在时，会加next-key lock和gap lock（两把锁，间隙锁遍历到向下第一个不符合条件的值停止），查询记录不存在时，next-key lock退化为gap lock
    - 非唯一索引范围查询 -- 普通索引范围查询，next-key lock不会退化为间隙锁和记录锁

#### （13） MVCC

读提交和可重复读都是通过Read View实现的，区别在于创建Read View的时机不同，读提交是在每个读取数据前都生成一个Read View，而可重复读是启动事务时生成一个Read View，然后整个事务期间都用这个Read View。

Read View的四个字段：

- m_ids: 创建Read View时当前数据库中活跃且未提交的事务的**事务id列表**
- min_trx_id:创建Read View时当前数据库中活跃且为提交的事务中最小事务id
- max_trx_id:创建Read View时当前数据库中应该给下一个事务的id值
- creator_trx_id:创建该Read View的事务id

聚集索引记录中两个隐藏列：

- trx_id: 当一个事务对某条聚集索引记录进行修改时，就会把该事务的事务id记录在trx_id隐藏列中
- roll_pointer: 每次对某条聚集索引记录进行改动时，都会把旧版本的记录写入到undo日志中，然后用这个隐藏列（指针）指向每个旧版本记录，从而可以找到修改前的记录

可重复读隔离级别下，读取数据时，在找到数据后，先会比较记录的trx_id和事务的Read View中的creatoor_trx_id，如果记录的trx_id比creator_trx_id小，且不在m_ids列表里，则意味着数据在事务创建之前提交，所以记录对事务可见；反之，如果记录的trx_id比creator_trx_id大，且在m_ids列表里，则意味着事务读到的是和自己一起启动的另一个事务修改的，不应该读取这条记录，而是沿着undo log链条往下找旧版本的记录，直到找到trx_id等于或小于该事务id的第一条记录。 => 这种方式就叫做多版本并发控制（MVCC）

读提交隔离级别下，每个select都会生成一个新的Read View，如果事务期间多次读取同一条记录，前后两次可能不一致。通过判断记录的trx_id和事务的Read View中creator_trx_id，如果前者较大，且在m_ids列表中，说明记录被另一个事务修改过且尚未提交【因为如果提交了，这条记录的trx_id就不会在m_ids列表中】，此时沿着undo log往下查找；如果前者较小，且不在m_ids列表中，说明记录trx_id的事务已经提交过。

在可重复读隔离级别下，普通查询是**快照读**，其他都是**当前读**如update、insert、delete等，在执行前都会查询最新版本的数据，然后做进一步操作。

Innodb引擎为了解决【可重复读隔离级别】使用【当前读】造成的幻读问题，引出next-key锁。



#### (14) 索引为什么能提高查询性能

首先，数据存储在磁盘中，磁盘上数据存储很慢，提高磁盘性能主要通过减少I/O次数以及单次I/O有效数据量

其次，索引通过多阶使树变得更加矮胖，从而减少I/O次数

再次，通过B+树，将业务数据和索引数据分离，提高单次I/O有效数据量，从而减少I/O次数

最后，索引通过树数据的有序和二分查找，快速缩小数据范围 

---



### 额外的一些概念

#### 什么是启发式算法

它根据一条规则（或启发），保存上一步找到的方法，『附加』到当前步骤来进一步搜寻解决方法。有些算法根据特定规则，一步步的应用规则但不总是保留上一步找到的最佳方法。它们统称启发式算法。





----

### 设计模式

适配器模式：有时也称为包装，将一个类的接口转换成用户所期待的，做法是将类本身的接口包裹在在一个已存在的类中

代理模式：为其余对象提供一种代理以控制这个对象的访问，适用于一个对象不适合或不能直接引用另一个对象，而代理对象能在二者之间起到中介作用

#### 适配器模式和代理模式的区别

适配器模式是由于新旧接口不一致导致客户端无法匹配的问题，为了使用之前实现旧接口的服务，将新接口转化为旧接口

代理模式提供的接口与原始接口一致，但为了不将实现直接暴露给客户端，而是通过代理层获取访问权限和一些处理。
